# 政策文件LDA主题模型可视化分析系统 v2.0

一个面向学术研究的中文政策文本分析平台，基于Streamlit开发。系统集成了LDA主题建模、词频共现分析、文本聚类、时序演变、比较分析、引用网络、语义网络等多种分析功能，为政策研究者提供全方位的文本分析工具。

## ✨ 核心特性

- 🎯 **主题建模**：基于LDA算法的主题发现与可视化
- 📊 **文本统计**：字符数、词数、句数、TTR等多维度统计
- 🔢 **词频分析**：词频统计、词性筛选、共现网络
- 🎨 **聚类分类**：K-means/层次聚类、自动分类
- 📅 **时序分析**：关键词趋势、主题演变追踪
- 🔍 **比较分析**：文档相似度、差异关键词识别
- 📖 **引用分析**：引用关系提取、核心文档识别
- 🕸️ **语义网络**：概念关联、社区检测、中心性分析
- 📚 **专业词典**：自定义词典管理、术语识别
- 🏷️ **质性编码**：文本编码标注、编码体系管理

## 📁 系统架构

```
📊 政策文件LDA主题模型可视化分析系统
├── 📁 数据加载          # 文件上传、示例数据
├── ⚙️ 文本预处理        # 分词、停用词、专业词典管理
├── 📈 基础文本分析      # 文本统计、词频分析、词语共现
├── 🎯 主题建模          # LDA模型训练、参数优化
├── 📊 主题可视化        # 词云、pyLDAvis、热图
├── 🔬 高级研究分析      # 聚类、时序、比较、引用、语义网络
└── 💾 结果导出          # 报告、CSV、模型保存
```

## 🚀 快速开始

### 环境要求

- Python 3.8+
- 推荐使用虚拟环境

### 安装依赖

```bash
pip install -r requirements.txt
```

### 运行应用

```bash
streamlit run app.py
```

浏览器访问 `http://localhost:8501` 即可使用。

## 📖 使用流程

### 1. 数据加载
- 上传TXT文件（单个/多个/ZIP压缩包）
- 或使用内置示例数据快速体验

### 2. 文本预处理
- 配置分词参数（最小词长、词频阈值）
- 管理停用词（内置/自定义）
- 导入专业词典提高分词准确性

### 3. 基础文本分析
- **文本统计**：查看字符数、词数、句数、段落数、TTR等指标
- **词频分析**：统计高频词，支持词性筛选
- **词语共现**：计算共现关系，生成共现网络图

### 4. 主题建模
- 设置主题数量（支持自动寻优）
- 配置迭代次数、passes等参数
- 查看连贯性分数和困惑度评估

### 5. 主题可视化
- 主题词云：直观展示各主题关键词
- pyLDAvis：交互式主题探索
- 文档-主题分布热图
- 主题相似性网络

### 6. 高级研究分析
- **聚类分类**：文档自动聚类，支持手动标注分类
- **时序分析**：追踪关键词和主题的时间演变
- **比较分析**：计算文档相似度，识别共同/差异关键词
- **引用分析**：提取引用关系，构建引用网络
- **语义网络**：构建概念网络，进行社区检测和中心性分析
- **质性编码**：创建编码体系，对文本片段进行主题编码标注

### 7. 结果导出
- 导出完整分析报告（HTML/PDF）
- 导出数据表格（CSV）
- 保存训练模型供后续使用

## 🗂️ 项目结构

```
├── app.py                    # 主应用入口
├── modules/                  # 功能模块
│   ├── data_loader.py       # 数据加载
│   ├── text_processor.py    # 文本预处理
│   ├── dictionary_manager.py # 专业词典管理
│   ├── text_statistics.py   # 文本统计分析
│   ├── frequency_analyzer.py # 词频与共现分析
│   ├── model_trainer.py     # LDA模型训练
│   ├── visualizer.py        # 主题可视化
│   ├── clustering_module.py # 聚类分类
│   ├── temporal_analyzer.py # 时序分析
│   ├── comparative_analyzer.py # 比较分析
│   ├── citation_analyzer.py # 引用分析
│   ├── semantic_network.py  # 语义网络
│   ├── qualitative_coding.py # 质性编码
│   ├── exporter.py          # 结果导出
│   └── sidebar.py           # 侧边栏
├── utils/
│   └── session_state.py     # 会话状态管理
├── tests/                   # 测试文件
├── data/                    # 数据目录
├── models/                  # 模型保存目录
└── results/                 # 结果输出目录
```

## 🛠️ 技术栈

| 类别 | 技术 |
|------|------|
| Web框架 | Streamlit |
| 主题模型 | Gensim (LDA) |
| 中文分词 | jieba |
| 数据处理 | Pandas, NumPy |
| 可视化 | Plotly, Matplotlib, PyLDAvis, WordCloud |
| 网络分析 | NetworkX |
| 降维算法 | UMAP, t-SNE |
| 测试框架 | pytest, hypothesis |

## 📝 注意事项

- 推荐使用5-50个政策文本进行分析
- 主题数量一般设置为4-10个较为合适
- 页面刷新会导致数据丢失，请及时保存
- 大规模文本分析可能需要较长处理时间

## 🧪 测试

项目使用 pytest 和 hypothesis 进行属性测试，确保核心功能的正确性。

```bash
# 运行所有测试
python -m pytest tests/ -v

# 运行特定模块测试
python -m pytest tests/test_text_statistics_properties.py -v
```

### 测试覆盖的属性

| 模块 | 属性测试 |
|------|----------|
| 文本统计 | 统计一致性、TTR范围 |
| 词频分析 | 词频统计正确性、词性筛选 |
| 共现分析 | 阈值过滤正确性 |
| 聚类分类 | 聚类完整性、分类覆盖 |
| 时序分析 | 时序排序正确性 |
| 比较分析 | 相似度对称性 |
| 引用分析 | 网络一致性、核心文档排序 |
| 语义网络 | 社区覆盖、中心性范围 |
| 词典管理 | 导入导出一致性、分词效果 |
| 质性编码 | 持久化一致性 |

## 📄 许可证

MIT License
