# -*- coding: utf-8 -*-
"""
è¯é¢‘ä¸å…±ç°åˆ†ææ¨¡å— (Word Frequency and Co-occurrence Analysis Module)

æœ¬æ¨¡å—æä¾›è¯é¢‘ç»Ÿè®¡å’Œè¯è¯­å…±ç°åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- è¯é¢‘ç»Ÿè®¡ä¸æ’åº
- è¯æ€§ç­›é€‰
- å…±ç°å…³ç³»è®¡ç®—
- å…±ç°ç½‘ç»œæ•°æ®è½¬æ¢
- ç»“æœå¯¼å‡º

Requirements: 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7
"""

from typing import List, Dict, Tuple, Optional, Set
from collections import Counter, defaultdict
from dataclasses import dataclass, field
import pandas as pd


class FrequencyAnalyzer:
    """
    è¯é¢‘åˆ†æå™¨ - ç»Ÿè®¡è¯è¯­é¢‘ç‡å¹¶æ”¯æŒè¯æ€§ç­›é€‰
    
    Attributes:
        texts: åˆ†è¯åçš„æ–‡æœ¬åˆ—è¡¨ï¼ˆæ¯ä¸ªæ–‡æœ¬æ˜¯è¯è¯­åˆ—è¡¨ï¼‰
        pos_tags: è¯æ€§æ ‡æ³¨åˆ—è¡¨ï¼ˆä¸textså¯¹åº”ï¼Œå¯é€‰ï¼‰
    
    Requirements: 2.1, 2.2
    """
    
    def __init__(self, texts: List[List[str]], pos_tags: Optional[List[List[str]]] = None):
        """
        åˆå§‹åŒ–è¯é¢‘åˆ†æå™¨
        
        Args:
            texts: åˆ†è¯åçš„æ–‡æœ¬åˆ—è¡¨
            pos_tags: è¯æ€§æ ‡æ³¨åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        """
        self.texts = texts if texts else []
        self.pos_tags = pos_tags
        self._word_frequency: Optional[Dict[str, int]] = None
        self._word_pos_map: Optional[Dict[str, Set[str]]] = None
    
    def _build_word_pos_map(self) -> Dict[str, Set[str]]:
        """
        æ„å»ºè¯è¯­åˆ°è¯æ€§çš„æ˜ å°„
        
        Returns:
            Dict[str, Set[str]]: è¯è¯­ -> è¯æ€§é›†åˆ
        """
        if self._word_pos_map is not None:
            return self._word_pos_map
        
        self._word_pos_map = defaultdict(set)
        
        if self.pos_tags:
            for text_idx, text in enumerate(self.texts):
                if text_idx < len(self.pos_tags):
                    pos_list = self.pos_tags[text_idx]
                    for word_idx, word in enumerate(text):
                        if word_idx < len(pos_list):
                            self._word_pos_map[word].add(pos_list[word_idx])
        
        return self._word_pos_map
    
    def calculate_word_frequency(self) -> Dict[str, int]:
        """
        è®¡ç®—æ‰€æœ‰è¯è¯­çš„å‡ºç°é¢‘ç‡
        
        Returns:
            Dict[str, int]: è¯è¯­é¢‘ç‡å­—å…¸
        
        Requirements: 2.1
        """
        if self._word_frequency is not None:
            return self._word_frequency
        
        counter = Counter()
        for text in self.texts:
            counter.update(text)
        
        self._word_frequency = dict(counter)
        return self._word_frequency
    
    def get_total_word_count(self) -> int:
        """
        è·å–æ–‡æœ¬ä¸­çš„æ€»è¯æ•°
        
        Returns:
            int: æ€»è¯æ•°
        """
        return sum(len(text) for text in self.texts)
    
    def filter_by_pos(self, pos_list: List[str]) -> Dict[str, int]:
        """
        æŒ‰è¯æ€§ç­›é€‰è¯é¢‘ç»Ÿè®¡ç»“æœ
        
        Args:
            pos_list: è¦ä¿ç•™çš„è¯æ€§åˆ—è¡¨
        
        Returns:
            Dict[str, int]: ç­›é€‰åçš„è¯é¢‘å­—å…¸
        
        Requirements: 2.2
        """
        if not self.pos_tags:
            # æ²¡æœ‰è¯æ€§æ ‡æ³¨æ—¶è¿”å›ç©ºå­—å…¸
            return {}
        
        word_pos_map = self._build_word_pos_map()
        word_freq = self.calculate_word_frequency()
        
        # ç­›é€‰æŒ‡å®šè¯æ€§çš„è¯è¯­
        pos_set = set(pos_list)
        filtered = {}
        
        for word, freq in word_freq.items():
            word_pos = word_pos_map.get(word, set())
            # å¦‚æœè¯è¯­çš„ä»»ä¸€è¯æ€§åœ¨æŒ‡å®šåˆ—è¡¨ä¸­ï¼Œåˆ™ä¿ç•™
            if word_pos & pos_set:
                filtered[word] = freq
        
        return filtered
    
    def get_top_words(self, n: int, pos_filter: Optional[List[str]] = None) -> List[Tuple[str, int]]:
        """
        è·å–é¢‘ç‡æœ€é«˜çš„nä¸ªè¯è¯­
        
        Args:
            n: è¿”å›çš„è¯è¯­æ•°é‡
            pos_filter: è¯æ€§ç­›é€‰åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            List[Tuple[str, int]]: (è¯è¯­, é¢‘ç‡) åˆ—è¡¨ï¼ŒæŒ‰é¢‘ç‡é™åºæ’åˆ—
        """
        if pos_filter:
            word_freq = self.filter_by_pos(pos_filter)
        else:
            word_freq = self.calculate_word_frequency()
        
        # æŒ‰é¢‘ç‡é™åºæ’åº
        sorted_words = sorted(word_freq.items(), key=lambda x: (-x[1], x[0]))
        return sorted_words[:n]
    
    def get_word_pos(self, word: str) -> Set[str]:
        """
        è·å–è¯è¯­çš„è¯æ€§æ ‡æ³¨
        
        Args:
            word: è¯è¯­
        
        Returns:
            Set[str]: è¯æ€§é›†åˆ
        """
        word_pos_map = self._build_word_pos_map()
        return word_pos_map.get(word, set())
    
    def export_frequency_csv(self, include_pos: bool = False) -> str:
        """
        å¯¼å‡ºè¯é¢‘ç»Ÿè®¡ç»“æœä¸ºCSVæ ¼å¼
        
        Args:
            include_pos: æ˜¯å¦åŒ…å«è¯æ€§ä¿¡æ¯
        
        Returns:
            str: CSVæ ¼å¼å­—ç¬¦ä¸²
        
        Requirements: 2.7
        """
        word_freq = self.calculate_word_frequency()
        sorted_words = sorted(word_freq.items(), key=lambda x: (-x[1], x[0]))
        
        if include_pos and self.pos_tags:
            word_pos_map = self._build_word_pos_map()
            data = [
                {
                    "è¯è¯­": word,
                    "é¢‘ç‡": freq,
                    "è¯æ€§": ",".join(sorted(word_pos_map.get(word, set())))
                }
                for word, freq in sorted_words
            ]
        else:
            data = [{"è¯è¯­": word, "é¢‘ç‡": freq} for word, freq in sorted_words]
        
        df = pd.DataFrame(data)
        return df.to_csv(index=False, encoding='utf-8-sig')


class CooccurrenceAnalyzer:
    """
    å…±ç°åˆ†æå™¨ - è®¡ç®—è¯è¯­é—´çš„å…±ç°å…³ç³»
    
    Attributes:
        texts: åˆ†è¯åçš„æ–‡æœ¬åˆ—è¡¨
        window_size: å…±ç°çª—å£å¤§å°
    
    Requirements: 2.3, 2.5
    """
    
    def __init__(self, texts: List[List[str]], window_size: int = 5):
        """
        åˆå§‹åŒ–å…±ç°åˆ†æå™¨
        
        Args:
            texts: åˆ†è¯åçš„æ–‡æœ¬åˆ—è¡¨
            window_size: å…±ç°çª—å£å¤§å°ï¼ˆé»˜è®¤5ï¼‰
        """
        self.texts = texts if texts else []
        self.window_size = max(1, window_size)
        self._cooccurrence_matrix: Optional[Dict[Tuple[str, str], int]] = None
    
    def calculate_cooccurrence(self) -> Dict[Tuple[str, str], int]:
        """
        è®¡ç®—è¯è¯­é—´çš„å…±ç°é¢‘ç‡
        
        ä½¿ç”¨æ»‘åŠ¨çª—å£æ–¹æ³•è®¡ç®—å…±ç°å…³ç³»ã€‚
        å…±ç°å¯¹æŒ‰å­—å…¸åºå­˜å‚¨ï¼Œç¡®ä¿ (A, B) å’Œ (B, A) è¢«è§†ä¸ºåŒä¸€å¯¹ã€‚
        
        Returns:
            Dict[Tuple[str, str], int]: å…±ç°é¢‘ç‡å­—å…¸ï¼Œé”®ä¸ºè¯è¯­å¯¹å…ƒç»„
        
        Requirements: 2.3
        """
        if self._cooccurrence_matrix is not None:
            return self._cooccurrence_matrix
        
        cooccurrence = Counter()
        
        for text in self.texts:
            text_len = len(text)
            for i, word1 in enumerate(text):
                # åœ¨çª—å£èŒƒå›´å†…æŸ¥æ‰¾å…±ç°è¯
                window_end = min(i + self.window_size + 1, text_len)
                for j in range(i + 1, window_end):
                    word2 = text[j]
                    if word1 != word2:
                        # æŒ‰å­—å…¸åºæ’åˆ—ï¼Œç¡®ä¿ä¸€è‡´æ€§
                        pair = tuple(sorted([word1, word2]))
                        cooccurrence[pair] += 1
        
        self._cooccurrence_matrix = dict(cooccurrence)
        return self._cooccurrence_matrix
    
    def filter_by_threshold(self, min_freq: int) -> Dict[Tuple[str, str], int]:
        """
        æŒ‰æœ€å°é¢‘ç‡é˜ˆå€¼è¿‡æ»¤å…±ç°ç»“æœ
        
        Args:
            min_freq: æœ€å°å…±ç°é¢‘ç‡é˜ˆå€¼
        
        Returns:
            Dict[Tuple[str, str], int]: è¿‡æ»¤åçš„å…±ç°é¢‘ç‡å­—å…¸
        
        Requirements: 2.5
        """
        cooccurrence = self.calculate_cooccurrence()
        return {
            pair: freq 
            for pair, freq in cooccurrence.items() 
            if freq >= min_freq
        }
    
    def get_top_cooccurrences(self, n: int, min_freq: int = 1) -> List[Tuple[Tuple[str, str], int]]:
        """
        è·å–å…±ç°é¢‘ç‡æœ€é«˜çš„nå¯¹è¯è¯­
        
        Args:
            n: è¿”å›çš„è¯è¯­å¯¹æ•°é‡
            min_freq: æœ€å°å…±ç°é¢‘ç‡é˜ˆå€¼
        
        Returns:
            List[Tuple[Tuple[str, str], int]]: ((è¯è¯­1, è¯è¯­2), é¢‘ç‡) åˆ—è¡¨
        """
        filtered = self.filter_by_threshold(min_freq)
        sorted_pairs = sorted(filtered.items(), key=lambda x: (-x[1], x[0]))
        return sorted_pairs[:n]
    
    def get_word_cooccurrences(self, word: str, min_freq: int = 1) -> Dict[str, int]:
        """
        è·å–æŒ‡å®šè¯è¯­çš„æ‰€æœ‰å…±ç°è¯åŠé¢‘ç‡
        
        Args:
            word: ç›®æ ‡è¯è¯­
            min_freq: æœ€å°å…±ç°é¢‘ç‡é˜ˆå€¼
        
        Returns:
            Dict[str, int]: å…±ç°è¯ -> é¢‘ç‡
        """
        cooccurrence = self.calculate_cooccurrence()
        result = {}
        
        for pair, freq in cooccurrence.items():
            if freq >= min_freq:
                if pair[0] == word:
                    result[pair[1]] = freq
                elif pair[1] == word:
                    result[pair[0]] = freq
        
        return result
    
    def to_network_data(self, min_freq: int = 1, max_nodes: int = 100) -> Tuple[List[dict], List[dict]]:
        """
        å°†å…±ç°æ•°æ®è½¬æ¢ä¸ºç½‘ç»œå›¾æ•°æ®æ ¼å¼
        
        Args:
            min_freq: æœ€å°å…±ç°é¢‘ç‡é˜ˆå€¼
            max_nodes: æœ€å¤§èŠ‚ç‚¹æ•°é‡
        
        Returns:
            Tuple[List[dict], List[dict]]: (èŠ‚ç‚¹åˆ—è¡¨, è¾¹åˆ—è¡¨)
            - èŠ‚ç‚¹æ ¼å¼: {"id": str, "label": str, "size": int}
            - è¾¹æ ¼å¼: {"source": str, "target": str, "weight": int}
        
        Requirements: 2.4
        """
        filtered = self.filter_by_threshold(min_freq)
        
        if not filtered:
            return [], []
        
        # ç»Ÿè®¡èŠ‚ç‚¹å‡ºç°æ¬¡æ•°ï¼ˆç”¨äºç¡®å®šèŠ‚ç‚¹å¤§å°ï¼‰
        node_counts = Counter()
        for (word1, word2), freq in filtered.items():
            node_counts[word1] += freq
            node_counts[word2] += freq
        
        # é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼Œä¿ç•™å‡ºç°é¢‘ç‡æœ€é«˜çš„èŠ‚ç‚¹
        top_nodes = [word for word, _ in node_counts.most_common(max_nodes)]
        top_nodes_set = set(top_nodes)
        
        # æ„å»ºèŠ‚ç‚¹åˆ—è¡¨
        nodes = [
            {
                "id": word,
                "label": word,
                "size": node_counts[word]
            }
            for word in top_nodes
        ]
        
        # æ„å»ºè¾¹åˆ—è¡¨ï¼ˆåªä¿ç•™ä¸¤ç«¯éƒ½åœ¨top_nodesä¸­çš„è¾¹ï¼‰
        edges = []
        for (word1, word2), freq in filtered.items():
            if word1 in top_nodes_set and word2 in top_nodes_set:
                edges.append({
                    "source": word1,
                    "target": word2,
                    "weight": freq
                })
        
        return nodes, edges
    
    def export_matrix_csv(self, min_freq: int = 1) -> str:
        """
        å¯¼å‡ºå…±ç°çŸ©é˜µä¸ºCSVæ ¼å¼
        
        Args:
            min_freq: æœ€å°å…±ç°é¢‘ç‡é˜ˆå€¼
        
        Returns:
            str: CSVæ ¼å¼å­—ç¬¦ä¸²
        
        Requirements: 2.7
        """
        filtered = self.filter_by_threshold(min_freq)
        sorted_pairs = sorted(filtered.items(), key=lambda x: (-x[1], x[0]))
        
        data = [
            {"è¯è¯­1": pair[0], "è¯è¯­2": pair[1], "å…±ç°é¢‘ç‡": freq}
            for pair, freq in sorted_pairs
        ]
        
        df = pd.DataFrame(data)
        return df.to_csv(index=False, encoding='utf-8-sig')
    
    def export_adjacency_matrix_csv(self, min_freq: int = 1, max_words: int = 50) -> str:
        """
        å¯¼å‡ºé‚»æ¥çŸ©é˜µæ ¼å¼çš„å…±ç°æ•°æ®
        
        Args:
            min_freq: æœ€å°å…±ç°é¢‘ç‡é˜ˆå€¼
            max_words: æœ€å¤§è¯è¯­æ•°é‡
        
        Returns:
            str: CSVæ ¼å¼çš„é‚»æ¥çŸ©é˜µ
        """
        filtered = self.filter_by_threshold(min_freq)
        
        if not filtered:
            return ""
        
        # è·å–æ‰€æœ‰è¯è¯­å¹¶é™åˆ¶æ•°é‡
        all_words = set()
        for word1, word2 in filtered.keys():
            all_words.add(word1)
            all_words.add(word2)
        
        # æŒ‰æ€»å…±ç°é¢‘ç‡æ’åºï¼Œå–å‰max_wordsä¸ª
        word_freq = Counter()
        for (word1, word2), freq in filtered.items():
            word_freq[word1] += freq
            word_freq[word2] += freq
        
        top_words = [w for w, _ in word_freq.most_common(max_words)]
        top_words_set = set(top_words)
        
        # æ„å»ºé‚»æ¥çŸ©é˜µ
        matrix = {word: {w: 0 for w in top_words} for word in top_words}
        
        for (word1, word2), freq in filtered.items():
            if word1 in top_words_set and word2 in top_words_set:
                matrix[word1][word2] = freq
                matrix[word2][word1] = freq
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(matrix, index=top_words, columns=top_words)
        return df.to_csv(encoding='utf-8-sig')




# ============================================================================
# Streamlit UI æ¸²æŸ“å‡½æ•°
# ============================================================================

def render_frequency_analyzer():
    """
    æ¸²æŸ“è¯é¢‘åˆ†ææ¨¡å—UI
    
    Requirements: 2.4, 2.7
    """
    import streamlit as st
    from utils.session_state import log_message
    
    st.header("è¯é¢‘åˆ†æ")
    
    # åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ
    with st.expander("ğŸ“– åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ", expanded=False):
        st.markdown("""
        ## ğŸ“Š è¯é¢‘åˆ†ææ¨¡å—
        
        **åŠŸèƒ½æ¦‚è¿°**ï¼šç»Ÿè®¡æ–‡æœ¬ä¸­è¯è¯­çš„å‡ºç°é¢‘ç‡ï¼Œæ”¯æŒè¯æ€§ç­›é€‰å’Œå¯è§†åŒ–å±•ç¤ºã€‚
        
        ---
        
        ### ğŸ¯ ä½¿ç”¨åœºæ™¯
        
        | åœºæ™¯ | æ“ä½œå»ºè®® | åº”ç”¨ |
        |------|----------|------|
        | äº†è§£æ–‡æœ¬ä¸»é¢˜ | æŸ¥çœ‹é«˜é¢‘è¯ | å¿«é€ŸæŠŠæ¡æ–‡æœ¬æ ¸å¿ƒå†…å®¹ |
        | æå–å…³é”®è¯ | ç­›é€‰åè¯ | æå–æ–‡æœ¬ä¸­çš„å…³é”®æ¦‚å¿µ |
        | åˆ†æåŠ¨ä½œå€¾å‘ | ç­›é€‰åŠ¨è¯ | äº†è§£æ”¿ç­–çš„è¡ŒåŠ¨å¯¼å‘ |
        | æƒ…æ„Ÿåˆ†æå‡†å¤‡ | ç­›é€‰å½¢å®¹è¯ | ä¸ºæƒ…æ„Ÿåˆ†ææä¾›åŸºç¡€ |
        
        ---
        
        ### ğŸ“‹ æ“ä½œæ­¥éª¤
        
        **åŸºç¡€è¯é¢‘åˆ†æ**ï¼š
        1. è®¾ç½®æ˜¾ç¤ºè¯è¯­æ•°é‡ï¼ˆ10-200ï¼‰
        2. é€‰æ‹©è¯æ€§ç­›é€‰ï¼ˆå¯é€‰ï¼‰
        3. ç‚¹å‡»"å¼€å§‹åˆ†æ"
        4. æŸ¥çœ‹è¯é¢‘è¡¨æ ¼å’Œå›¾è¡¨
        5. ä¸‹è½½CSVæ–‡ä»¶
        
        **è¯æ€§ç­›é€‰åˆ†æ**ï¼š
        1. åœ¨è¯æ€§ç­›é€‰ä¸‹æ‹‰æ¡†é€‰æ‹©è¯æ€§
        2. å¯é€‰ï¼šåè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯ã€è‡ªå®šä¹‰
        3. è‡ªå®šä¹‰æ—¶è¾“å…¥è¯æ€§æ ‡ç­¾ï¼ˆå¦‚n,v,aï¼‰
        4. ç‚¹å‡»"å¼€å§‹åˆ†æ"
        
        ---
        
        ### âš™ï¸ å‚æ•°è¯´æ˜
        
        | å‚æ•° | èŒƒå›´ | é»˜è®¤å€¼ | è¯´æ˜ |
        |------|------|--------|------|
        | æ˜¾ç¤ºè¯è¯­æ•°é‡ | 10-200 | 50 | æ˜¾ç¤ºé¢‘ç‡æœ€é«˜çš„Nä¸ªè¯ |
        | è¯æ€§ç­›é€‰ | å¤šé€‰ | å…¨éƒ¨ | åªç»Ÿè®¡æŒ‡å®šè¯æ€§çš„è¯è¯­ |
        
        ---
        
        ### ğŸ·ï¸ è¯æ€§æ ‡ç­¾è¯´æ˜
        
        | è¯æ€§ | æ ‡ç­¾ | ç¤ºä¾‹ |
        |------|------|------|
        | åè¯ | n, nr, ns, nt, nz | æ”¿ç­–ã€å‘å±•ã€åˆ›æ–° |
        | åŠ¨è¯ | v, vd, vn | æ¨è¿›ã€å®æ–½ã€åŠ å¼º |
        | å½¢å®¹è¯ | a, ad, an | é‡è¦ã€å…¨é¢ã€æ·±å…¥ |
        | å‰¯è¯ | d | è¿›ä¸€æ­¥ã€åˆ‡å®ã€å…¨é¢ |
        
        ---
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè®®
        
        **å­¦æœ¯ç ”ç©¶å»ºè®®**ï¼š
        - å¯¼å‡ºè¯é¢‘è¡¨ä½œä¸ºè®ºæ–‡é™„å½•
        - ç»“åˆè¯æ€§ç­›é€‰åˆ†æä¸åŒç±»å‹è¯è¯­çš„åˆ†å¸ƒ
        - é«˜é¢‘è¯å¯ä½œä¸ºä¸»é¢˜åˆ†æçš„å‚è€ƒ
        
        **æ”¿ç­–åˆ†æå»ºè®®**ï¼š
        - åè¯é«˜é¢‘è¯åæ˜ æ”¿ç­–å…³æ³¨çš„é¢†åŸŸ
        - åŠ¨è¯é«˜é¢‘è¯åæ˜ æ”¿ç­–çš„è¡ŒåŠ¨å¯¼å‘
        - å½¢å®¹è¯é«˜é¢‘è¯åæ˜ æ”¿ç­–çš„ä»·å€¼å–å‘
        
        ---
        
        ### â“ å¸¸è§é—®é¢˜
        
        **Q: è¯æ€§ç­›é€‰ä¸å¯ç”¨æ€ä¹ˆåŠï¼Ÿ**
        A: è¯æ€§ç­›é€‰éœ€è¦åœ¨é¢„å¤„ç†æ—¶å¯ç”¨è¯æ€§æ ‡æ³¨åŠŸèƒ½ã€‚
        
        **Q: å¦‚ä½•åˆ¤æ–­è¯é¢‘åˆ†æç»“æœçš„è´¨é‡ï¼Ÿ**
        A: é«˜é¢‘è¯åº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„å®è¯ï¼Œå¦‚æœå‡ºç°å¤§é‡è™šè¯ï¼Œéœ€è¦è°ƒæ•´åœç”¨è¯è®¾ç½®ã€‚
        """)
    
    # æ£€æŸ¥æ•°æ®
    if not st.session_state.get("texts"):
        st.warning("è¯·å…ˆåœ¨ã€Œæ–‡æœ¬é¢„å¤„ç†ã€æ ‡ç­¾é¡µä¸­å®Œæˆæ–‡æœ¬é¢„å¤„ç†")
        return
    
    texts = st.session_state["texts"]
    pos_tags = st.session_state.get("pos_tags")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = FrequencyAnalyzer(texts, pos_tags)
    
    # å‚æ•°è®¾ç½®
    col1, col2 = st.columns(2)
    with col1:
        top_n = st.slider("æ˜¾ç¤ºè¯è¯­æ•°é‡", min_value=10, max_value=200, value=50, step=10)
    with col2:
        # è¯æ€§ç­›é€‰ï¼ˆå¦‚æœæœ‰è¯æ€§æ ‡æ³¨ï¼‰
        pos_filter = None
        if pos_tags:
            pos_options = ["å…¨éƒ¨", "åè¯(n)", "åŠ¨è¯(v)", "å½¢å®¹è¯(a)", "å‰¯è¯(d)", "è‡ªå®šä¹‰"]
            selected_pos = st.selectbox("è¯æ€§ç­›é€‰", pos_options)
            
            if selected_pos == "åè¯(n)":
                pos_filter = ["n", "nr", "ns", "nt", "nz", "ng"]
            elif selected_pos == "åŠ¨è¯(v)":
                pos_filter = ["v", "vd", "vn", "vg"]
            elif selected_pos == "å½¢å®¹è¯(a)":
                pos_filter = ["a", "ad", "an", "ag"]
            elif selected_pos == "å‰¯è¯(d)":
                pos_filter = ["d"]
            elif selected_pos == "è‡ªå®šä¹‰":
                custom_pos = st.text_input("è¾“å…¥è¯æ€§æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰", "n,v,a")
                pos_filter = [p.strip() for p in custom_pos.split(",") if p.strip()]
    
    # æ‰§è¡Œåˆ†æ
    if st.button("å¼€å§‹åˆ†æ", key="freq_analyze_btn", type="primary"):
        with st.spinner("æ­£åœ¨ç»Ÿè®¡è¯é¢‘..."):
            # è·å–è¯é¢‘
            top_words = analyzer.get_top_words(top_n, pos_filter)
            
            if top_words:
                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                st.session_state["word_frequency"] = dict(top_words)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                total_words = analyzer.get_total_word_count()
                unique_words = len(analyzer.calculate_word_frequency())
                
                col1, col2, col3 = st.columns(3)
                col1.metric("æ€»è¯æ•°", f"{total_words:,}")
                col2.metric("ä¸åŒè¯æ±‡æ•°", f"{unique_words:,}")
                col3.metric("æ˜¾ç¤ºè¯æ±‡æ•°", len(top_words))
                
                log_message(f"è¯é¢‘åˆ†æå®Œæˆï¼Œå…± {unique_words} ä¸ªä¸åŒè¯æ±‡")
            else:
                st.warning("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è¯è¯­")
    
    # æ˜¾ç¤ºç»“æœ
    if st.session_state.get("word_frequency"):
        word_freq = st.session_state["word_frequency"]
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        result_tabs = st.tabs(["ğŸ“Š è¯é¢‘è¡¨æ ¼", "ğŸ“ˆ è¯é¢‘å›¾è¡¨", "ğŸ’¾ å¯¼å‡º"])
        
        # è¯é¢‘è¡¨æ ¼
        with result_tabs[0]:
            df = pd.DataFrame(
                list(word_freq.items()),
                columns=["è¯è¯­", "é¢‘ç‡"]
            )
            df["æ’å"] = range(1, len(df) + 1)
            df = df[["æ’å", "è¯è¯­", "é¢‘ç‡"]]
            
            st.dataframe(df, use_container_width=True, hide_index=True, height=400)
        
        # è¯é¢‘å›¾è¡¨
        with result_tabs[1]:
            try:
                import plotly.express as px
                
                # å–å‰30ä¸ªè¯æ˜¾ç¤º
                display_words = list(word_freq.items())[:30]
                chart_df = pd.DataFrame(display_words, columns=["è¯è¯­", "é¢‘ç‡"])
                
                fig = px.bar(
                    chart_df,
                    x="è¯è¯­",
                    y="é¢‘ç‡",
                    title="è¯é¢‘åˆ†å¸ƒï¼ˆå‰30ä¸ªè¯ï¼‰",
                    color="é¢‘ç‡",
                    color_continuous_scale="Blues"
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig, use_container_width=True)
                
            except ImportError:
                st.warning("éœ€è¦å®‰è£…plotlyåº“æ‰èƒ½æ˜¾ç¤ºå›¾è¡¨: pip install plotly")
                # ä½¿ç”¨StreamlitåŸç”Ÿå›¾è¡¨
                chart_df = pd.DataFrame(
                    list(word_freq.items())[:20],
                    columns=["è¯è¯­", "é¢‘ç‡"]
                )
                st.bar_chart(chart_df.set_index("è¯è¯­"))
        
        # å¯¼å‡º
        with result_tabs[2]:
            csv_content = analyzer.export_frequency_csv(include_pos=bool(pos_tags))
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è¯é¢‘è¡¨CSV",
                data=csv_content,
                file_name="word_frequency.csv",
                mime="text/csv"
            )


def render_cooccurrence_analyzer():
    """
    æ¸²æŸ“è¯è¯­å…±ç°åˆ†ææ¨¡å—UI
    
    Requirements: 2.4, 2.6, 2.7
    """
    import streamlit as st
    from utils.session_state import log_message
    
    st.header("è¯è¯­å…±ç°åˆ†æ")
    
    # åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ
    with st.expander("ğŸ“– åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ", expanded=False):
        st.markdown("""
        ## ğŸ”— è¯è¯­å…±ç°åˆ†ææ¨¡å—
        
        **åŠŸèƒ½æ¦‚è¿°**ï¼šåˆ†æè¯è¯­é—´çš„å…±ç°å…³ç³»ï¼Œæ­ç¤ºè¯è¯­ä¹‹é—´çš„è¯­ä¹‰å…³è”ã€‚
        
        ---
        
        ### ğŸ¯ ä½¿ç”¨åœºæ™¯
        
        | åœºæ™¯ | å…³æ³¨ç‚¹ | åº”ç”¨ |
        |------|--------|------|
        | æ¦‚å¿µå…³è”åˆ†æ | é«˜é¢‘å…±ç°è¯å¯¹ | å‘ç°æ¦‚å¿µä¹‹é—´çš„å…³è” |
        | è¯­ä¹‰ç½‘ç»œæ„å»º | å…±ç°ç½‘ç»œå›¾ | å¯è§†åŒ–è¯è¯­å…³ç³»ç½‘ç»œ |
        | å…³é”®è¯æ‰©å±• | ç‰¹å®šè¯çš„å…±ç°è¯ | æ‰©å±•å…³é”®è¯åˆ—è¡¨ |
        | ä¸»é¢˜å‘ç° | ç¤¾åŒºæ£€æµ‹ | å‘ç°æ½œåœ¨çš„ä¸»é¢˜èšç±» |
        
        ---
        
        ### ğŸ“‹ ç®—æ³•åŸç†
        
        **æ»‘åŠ¨çª—å£å…±ç°è®¡ç®—**ï¼š
        - åœ¨æ–‡æœ¬ä¸­è®¾ç½®å›ºå®šå¤§å°çš„çª—å£
        - ç»Ÿè®¡çª—å£å†…è¯è¯­å¯¹çš„å…±åŒå‡ºç°æ¬¡æ•°
        - çª—å£è¶Šå¤§ï¼Œæ•è·çš„å…³è”è¶Šè¿œ
        
        **ç¤ºä¾‹**ï¼šçª—å£å¤§å°=3ï¼Œæ–‡æœ¬="æ”¿ç­– æ¨åŠ¨ åˆ›æ–° å‘å±•"
        - (æ”¿ç­–, æ¨åŠ¨)ã€(æ”¿ç­–, åˆ›æ–°)ã€(æ¨åŠ¨, åˆ›æ–°)ã€(æ¨åŠ¨, å‘å±•)ã€(åˆ›æ–°, å‘å±•)
        
        ---
        
        ### âš™ï¸ å‚æ•°è¯´æ˜
        
        | å‚æ•° | èŒƒå›´ | é»˜è®¤å€¼ | è¯´æ˜ |
        |------|------|--------|------|
        | å…±ç°çª—å£å¤§å° | 2-20 | 5 | è®¡ç®—å…±ç°çš„è¯è¯­èŒƒå›´ |
        | æœ€å°å…±ç°é¢‘ç‡ | 1-50 | 2 | è¿‡æ»¤ä½é¢‘å…±ç°å¯¹ |
        | æœ€å¤§èŠ‚ç‚¹æ•° | 20-200 | 50 | ç½‘ç»œå›¾æ˜¾ç¤ºçš„æœ€å¤§èŠ‚ç‚¹æ•° |
        
        **å‚æ•°è°ƒä¼˜å»ºè®®**ï¼š
        - çª—å£å¤§å°ï¼šå¥å­çº§åˆ†æç”¨3-5ï¼Œæ®µè½çº§åˆ†æç”¨10-15
        - æœ€å°é¢‘ç‡ï¼šæ•°æ®é‡å¤§æ—¶æé«˜ï¼Œæ•°æ®é‡å°æ—¶é™ä½
        - æœ€å¤§èŠ‚ç‚¹æ•°ï¼šæ ¹æ®å¯è§†åŒ–æ¸…æ™°åº¦è°ƒæ•´
        
        ---
        
        ### ğŸ“‹ æ“ä½œæ­¥éª¤
        
        **åŸºç¡€å…±ç°åˆ†æ**ï¼š
        1. è®¾ç½®å…±ç°çª—å£å¤§å°
        2. è®¾ç½®æœ€å°å…±ç°é¢‘ç‡
        3. è®¾ç½®æœ€å¤§èŠ‚ç‚¹æ•°
        4. ç‚¹å‡»"è®¡ç®—å…±ç°å…³ç³»"
        5. æŸ¥çœ‹å…±ç°ç½‘ç»œã€è¡¨æ ¼ã€æŸ¥è¯¢ç»“æœ
        
        **ç½‘ç»œå›¾æ ·å¼è®¾ç½®**ï¼š
        1. å±•å¼€"å›¾è¡¨æ ·å¼è®¾ç½®"
        2. é€‰æ‹©å¸ƒå±€ç®—æ³•ï¼ˆæ¨èspringåŠ›å¯¼å‘ï¼‰
        3. è°ƒæ•´èŠ‚ç‚¹å’Œè¾¹çš„æ ·å¼
        4. å¯å¯ç”¨ç¤¾åŒºæ£€æµ‹è¿›è¡Œèšç±»ç€è‰²
        
        **è¯è¯­æŸ¥è¯¢**ï¼š
        1. åˆ‡æ¢åˆ°"è¯è¯­æŸ¥è¯¢"æ ‡ç­¾é¡µ
        2. è¾“å…¥è¦æŸ¥è¯¢çš„è¯è¯­
        3. æŸ¥çœ‹è¯¥è¯çš„æ‰€æœ‰å…±ç°è¯
        
        ---
        
        ### ğŸ¨ å¸ƒå±€ç®—æ³•è¯´æ˜
        
        | ç®—æ³• | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
        |------|------|----------|
        | spring (åŠ›å¯¼å‘) | èŠ‚ç‚¹é—´æ¨¡æ‹Ÿå¼¹ç°§åŠ› | é€šç”¨ï¼Œæ¨èä½¿ç”¨ |
        | kamada_kawai | åŸºäºå›¾è®ºè·ç¦»ä¼˜åŒ– | å°å‹ç½‘ç»œ |
        | circular | èŠ‚ç‚¹å‡åŒ€åˆ†å¸ƒåœ¨åœ†å‘¨ | å±•ç¤ºè¿æ¥å…³ç³» |
        | shell | æŒ‰åº¦æ•°åˆ†å±‚åŒå¿ƒåœ† | å±•ç¤ºå±‚æ¬¡ç»“æ„ |
        
        ---
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè®®
        
        **å­¦æœ¯ç ”ç©¶å»ºè®®**ï¼š
        - æŠ¥å‘Šå…±ç°çª—å£å¤§å°å’Œæœ€å°é¢‘ç‡é˜ˆå€¼
        - å¯¼å‡ºå…±ç°çŸ©é˜µç”¨äºåç»­ç½‘ç»œåˆ†æ
        - ä½¿ç”¨ç¤¾åŒºæ£€æµ‹å‘ç°è¯è¯­èšç±»
        
        **å¯è§†åŒ–å»ºè®®**ï¼š
        - å­¦æœ¯è®ºæ–‡é…å›¾å»ºè®®ä½¿ç”¨"å­¦æœ¯è“"æˆ–"é»‘ç™½æ‰“å°"é…è‰²
        - è°ƒæ•´èŠ‚ç‚¹å¤§å°å’Œæ ‡ç­¾å­—ä½“ç¡®ä¿æ¸…æ™°å¯è¯»
        - å¯å¯¼å‡ºä¸ºé«˜åˆ†è¾¨ç‡å›¾ç‰‡
        
        ---
        
        ### â“ å¸¸è§é—®é¢˜
        
        **Q: å…±ç°ç½‘ç»œå¤ªå¯†é›†æ€ä¹ˆåŠï¼Ÿ**
        A: æé«˜æœ€å°å…±ç°é¢‘ç‡æˆ–å‡å°‘æœ€å¤§èŠ‚ç‚¹æ•°ã€‚
        
        **Q: å¦‚ä½•è§£è¯»å…±ç°ç½‘ç»œï¼Ÿ**
        A: è¿æ¥è¶Šå¤šçš„èŠ‚ç‚¹æ˜¯æ ¸å¿ƒè¯ï¼Œè¿æ¥è¶Šç²—çš„è¾¹è¡¨ç¤ºå…±ç°è¶Šé¢‘ç¹ã€‚
        
        **Q: ç¤¾åŒºæ£€æµ‹æœ‰ä»€ä¹ˆç”¨ï¼Ÿ**
        A: å¯ä»¥å‘ç°è¯­ä¹‰ç›¸è¿‘çš„è¯è¯­èšç±»ï¼Œä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒç¤¾åŒºã€‚
        """)
    
    # æ£€æŸ¥æ•°æ®
    if not st.session_state.get("texts"):
        st.warning("è¯·å…ˆåœ¨ã€Œæ–‡æœ¬é¢„å¤„ç†ã€æ ‡ç­¾é¡µä¸­å®Œæˆæ–‡æœ¬é¢„å¤„ç†")
        return
    
    texts = st.session_state["texts"]
    
    # å‚æ•°è®¾ç½®
    st.subheader("å‚æ•°è®¾ç½®")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        window_size = st.slider(
            "å…±ç°çª—å£å¤§å°",
            min_value=2,
            max_value=20,
            value=st.session_state.get("cooccurrence_window_size", 5),
            help="åœ¨å¤šå°‘ä¸ªè¯çš„èŒƒå›´å†…è®¡ç®—å…±ç°å…³ç³»"
        )
        st.session_state["cooccurrence_window_size"] = window_size
    
    with col2:
        min_freq = st.slider(
            "æœ€å°å…±ç°é¢‘ç‡",
            min_value=1,
            max_value=50,
            value=st.session_state.get("cooccurrence_min_freq", 2),
            help="è¿‡æ»¤å…±ç°é¢‘ç‡ä½äºæ­¤å€¼çš„è¯è¯­å¯¹"
        )
        st.session_state["cooccurrence_min_freq"] = min_freq
    
    with col3:
        max_nodes = st.slider(
            "æœ€å¤§èŠ‚ç‚¹æ•°",
            min_value=20,
            max_value=200,
            value=50,
            help="ç½‘ç»œå›¾ä¸­æ˜¾ç¤ºçš„æœ€å¤§èŠ‚ç‚¹æ•°é‡"
        )
    
    # æ‰§è¡Œåˆ†æ
    if st.button("è®¡ç®—å…±ç°å…³ç³»", key="cooc_analyze_btn", type="primary"):
        with st.spinner("æ­£åœ¨è®¡ç®—å…±ç°å…³ç³»..."):
            analyzer = CooccurrenceAnalyzer(texts, window_size)
            cooccurrence = analyzer.filter_by_threshold(min_freq)
            
            if cooccurrence:
                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                st.session_state["cooccurrence_matrix"] = cooccurrence
                st.session_state["cooccurrence_analyzer"] = analyzer
                
                st.success(f"å…±ç°åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(cooccurrence)} å¯¹å…±ç°è¯è¯­")
                log_message(f"å…±ç°åˆ†æå®Œæˆï¼Œçª—å£å¤§å°={window_size}ï¼Œæœ€å°é¢‘ç‡={min_freq}")
            else:
                st.warning("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å…±ç°è¯è¯­å¯¹ï¼Œè¯·å°è¯•é™ä½æœ€å°å…±ç°é¢‘ç‡")
    
    # æ˜¾ç¤ºç»“æœ
    if st.session_state.get("cooccurrence_matrix"):
        cooccurrence = st.session_state["cooccurrence_matrix"]
        analyzer = st.session_state.get("cooccurrence_analyzer")
        
        if analyzer is None:
            analyzer = CooccurrenceAnalyzer(texts, window_size)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        result_tabs = st.tabs(["ğŸ•¸ï¸ å…±ç°ç½‘ç»œ", "ğŸ“Š å…±ç°è¡¨æ ¼", "ğŸ” è¯è¯­æŸ¥è¯¢", "ğŸ’¾ å¯¼å‡º"])
        
        # å…±ç°ç½‘ç»œ
        with result_tabs[0]:
            st.subheader("å…±ç°ç½‘ç»œå›¾")
            
            # å­¦æœ¯è®ºæ–‡é£æ ¼è®¾ç½®
            with st.expander("ğŸ¨ å›¾è¡¨æ ·å¼è®¾ç½®", expanded=True):
                
                # ç¬¬ä¸€è¡Œï¼šå¸ƒå±€å’Œé…è‰²
                st.markdown("**ğŸ“ å¸ƒå±€ä¸é…è‰²**")
                layout_col1, layout_col2 = st.columns(2)
                
                with layout_col1:
                    layout_algorithm = st.selectbox(
                        "å¸ƒå±€ç®—æ³•",
                        [
                            "spring (åŠ›å¯¼å‘)",
                            "kamada_kawai (è·¯å¾„ä¼˜åŒ–)",
                            "fruchterman_reingold (FRç®—æ³•)",
                            "circular (åœ†å½¢)",
                            "shell (åŒå¿ƒåœ†)",
                            "spectral (è°±å¸ƒå±€)",
                            "random (éšæœº)",
                            "spiral (èºæ—‹)"
                        ],
                        index=0,
                        help="""
â€¢ spring: åŠ›å¯¼å‘å¸ƒå±€ï¼ŒèŠ‚ç‚¹é—´æ¨¡æ‹Ÿå¼¹ç°§åŠ›ï¼ˆæ¨èï¼‰
â€¢ kamada_kawai: åŸºäºå›¾è®ºè·ç¦»ä¼˜åŒ–ï¼Œé€‚åˆå°å‹ç½‘ç»œ
â€¢ fruchterman_reingold: ç»å…¸FRåŠ›å¯¼å‘ç®—æ³•
â€¢ circular: èŠ‚ç‚¹å‡åŒ€åˆ†å¸ƒåœ¨åœ†å‘¨ä¸Š
â€¢ shell: æŒ‰åº¦æ•°åˆ†å±‚çš„åŒå¿ƒåœ†å¸ƒå±€
â€¢ spectral: åŸºäºå›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„è°±å¸ƒå±€
â€¢ random: éšæœºå¸ƒå±€ï¼Œå¯ç”¨äºå¯¹æ¯”
â€¢ spiral: èºæ—‹å½¢å¸ƒå±€ï¼Œé€‚åˆå±•ç¤ºå±‚æ¬¡
                        """
                    )
                
                with layout_col2:
                    color_scheme = st.selectbox(
                        "é…è‰²æ–¹æ¡ˆ",
                        ["å­¦æœ¯è“", "ç»å…¸ç°", "æš–è‰²è°ƒ", "å†·è‰²è°ƒ", "å½©è™¹", "é»‘ç™½æ‰“å°"],
                        index=0,
                        help="é€‰æ‹©é€‚åˆå­¦æœ¯è®ºæ–‡çš„é…è‰²æ–¹æ¡ˆï¼Œé»‘ç™½æ‰“å°é€‚åˆç°åº¦å°åˆ·"
                    )
                
                st.markdown("---")
                
                # ç¬¬äºŒè¡Œï¼šèŠ‚ç‚¹è®¾ç½®
                st.markdown("**â­• èŠ‚ç‚¹è®¾ç½®**")
                node_col1, node_col2, node_col3, node_col4 = st.columns(4)
                
                with node_col1:
                    node_size_mode = st.selectbox(
                        "èŠ‚ç‚¹å¤§å°ä¾æ®",
                        ["åº¦æ•° (è¿æ¥æ•°)", "æƒé‡ (å…±ç°æ€»é¢‘ç‡)", "ç»Ÿä¸€å¤§å°"],
                        index=0,
                        help="é€‰æ‹©èŠ‚ç‚¹å¤§å°çš„è®¡ç®—æ–¹å¼"
                    )
                
                with node_col2:
                    node_size_scale = st.slider(
                        "èŠ‚ç‚¹å¤§å°æ¯”ä¾‹",
                        min_value=0.3,
                        max_value=3.0,
                        value=1.0,
                        step=0.1
                    )
                
                with node_col3:
                    node_shape = st.selectbox(
                        "èŠ‚ç‚¹å½¢çŠ¶",
                        ["åœ†å½¢", "æ–¹å½¢", "è±å½¢", "ä¸‰è§’å½¢"],
                        index=0
                    )
                
                with node_col4:
                    node_opacity = st.slider(
                        "èŠ‚ç‚¹é€æ˜åº¦",
                        min_value=0.3,
                        max_value=1.0,
                        value=0.9,
                        step=0.1
                    )
                
                st.markdown("---")
                
                # ç¬¬ä¸‰è¡Œï¼šè¾¹è®¾ç½®
                st.markdown("**â– è¾¹çº¿è®¾ç½®**")
                edge_col1, edge_col2, edge_col3, edge_col4 = st.columns(4)
                
                with edge_col1:
                    edge_width_mode = st.selectbox(
                        "è¾¹çº¿ç²—ç»†ä¾æ®",
                        ["æƒé‡ (å…±ç°é¢‘ç‡)", "ç»Ÿä¸€ç²—ç»†"],
                        index=0,
                        help="é€‰æ‹©è¾¹çº¿ç²—ç»†çš„è®¡ç®—æ–¹å¼"
                    )
                
                with edge_col2:
                    edge_width_scale = st.slider(
                        "è¾¹çº¿ç²—ç»†æ¯”ä¾‹",
                        min_value=0.3,
                        max_value=3.0,
                        value=1.0,
                        step=0.1
                    )
                
                with edge_col3:
                    edge_style = st.selectbox(
                        "è¾¹çº¿æ ·å¼",
                        ["å®çº¿", "è™šçº¿", "ç‚¹çº¿"],
                        index=0
                    )
                
                with edge_col4:
                    edge_opacity = st.slider(
                        "è¾¹çº¿é€æ˜åº¦",
                        min_value=0.1,
                        max_value=1.0,
                        value=0.6,
                        step=0.1
                    )
                
                st.markdown("---")
                
                # ç¬¬å››è¡Œï¼šæ ‡ç­¾è®¾ç½®
                st.markdown("**ğŸ·ï¸ æ ‡ç­¾è®¾ç½®**")
                label_col1, label_col2, label_col3, label_col4 = st.columns(4)
                
                with label_col1:
                    show_node_labels = st.checkbox(
                        "æ˜¾ç¤ºèŠ‚ç‚¹æ ‡ç­¾",
                        value=True
                    )
                
                with label_col2:
                    font_size = st.slider(
                        "æ ‡ç­¾å­—ä½“å¤§å°",
                        min_value=6,
                        max_value=24,
                        value=11
                    )
                
                with label_col3:
                    label_position = st.selectbox(
                        "æ ‡ç­¾ä½ç½®",
                        ["ä¸Šæ–¹", "ä¸‹æ–¹", "å³ä¾§", "å·¦ä¾§", "å±…ä¸­"],
                        index=0
                    )
                
                with label_col4:
                    show_edge_labels = st.checkbox(
                        "æ˜¾ç¤ºè¾¹æƒé‡",
                        value=False
                    )
                
                st.markdown("---")
                
                # ç¬¬äº”è¡Œï¼šé«˜çº§è®¾ç½®
                st.markdown("**âš™ï¸ é«˜çº§è®¾ç½®**")
                adv_col1, adv_col2, adv_col3, adv_col4 = st.columns(4)
                
                with adv_col1:
                    show_colorbar = st.checkbox(
                        "æ˜¾ç¤ºé¢œè‰²å›¾ä¾‹",
                        value=True,
                        help="æ˜¾ç¤ºèŠ‚ç‚¹é¢œè‰²å¯¹åº”çš„æ•°å€¼å›¾ä¾‹"
                    )
                
                with adv_col2:
                    show_title = st.checkbox(
                        "æ˜¾ç¤ºå›¾è¡¨æ ‡é¢˜",
                        value=True
                    )
                
                with adv_col3:
                    transparent_bg = st.checkbox(
                        "é€æ˜èƒŒæ™¯",
                        value=False,
                        help="å¯¼å‡ºæ—¶ä½¿ç”¨é€æ˜èƒŒæ™¯"
                    )
                
                with adv_col4:
                    show_stats_annotation = st.checkbox(
                        "æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯",
                        value=True,
                        help="åœ¨å›¾è¡¨åº•éƒ¨æ˜¾ç¤ºèŠ‚ç‚¹æ•°ã€è¾¹æ•°ç­‰"
                    )
                
                # ç¬¬å…­è¡Œï¼šç¤¾åŒºæ£€æµ‹
                st.markdown("---")
                st.markdown("**ğŸ”¬ ç¤¾åŒºæ£€æµ‹ï¼ˆèšç±»ç€è‰²ï¼‰**")
                community_col1, community_col2 = st.columns(2)
                
                with community_col1:
                    enable_community = st.checkbox(
                        "å¯ç”¨ç¤¾åŒºæ£€æµ‹",
                        value=False,
                        help="ä½¿ç”¨Louvainç®—æ³•æ£€æµ‹ç½‘ç»œç¤¾åŒºï¼Œä¸åŒç¤¾åŒºç”¨ä¸åŒé¢œè‰²æ ‡æ³¨"
                    )
                
                with community_col2:
                    if enable_community:
                        community_resolution = st.slider(
                            "ç¤¾åŒºç²’åº¦",
                            min_value=0.5,
                            max_value=2.0,
                            value=1.0,
                            step=0.1,
                            help="å€¼è¶Šå¤§ï¼Œæ£€æµ‹åˆ°çš„ç¤¾åŒºè¶Šå¤šè¶Šå°"
                        )
                    else:
                        community_resolution = 1.0
                
                # è‡ªå®šä¹‰æ ‡é¢˜
                if show_title:
                    custom_title = st.text_input(
                        "è‡ªå®šä¹‰å›¾è¡¨æ ‡é¢˜",
                        value="è¯è¯­å…±ç°ç½‘ç»œå›¾",
                        help="è¾“å…¥æ‚¨æƒ³è¦æ˜¾ç¤ºçš„å›¾è¡¨æ ‡é¢˜"
                    )
                else:
                    custom_title = ""
            
            nodes, edges = analyzer.to_network_data(min_freq, max_nodes)
            
            if nodes and edges:
                try:
                    import plotly.graph_objects as go
                    import networkx as nx
                    
                    # æ„å»ºNetworkXå›¾
                    G = nx.Graph()
                    for node in nodes:
                        G.add_node(node["id"], size=node["size"])
                    for edge in edges:
                        G.add_edge(edge["source"], edge["target"], weight=edge["weight"])
                    
                    # æ ¹æ®é€‰æ‹©çš„å¸ƒå±€ç®—æ³•è®¡ç®—ä½ç½®
                    layout_name = layout_algorithm.split(" ")[0]  # æå–ç®—æ³•åç§°
                    
                    if layout_name == "spring":
                        pos = nx.spring_layout(G, k=2, iterations=100, seed=42)
                    elif layout_name == "kamada_kawai":
                        try:
                            pos = nx.kamada_kawai_layout(G)
                        except:
                            pos = nx.spring_layout(G, k=2, iterations=100, seed=42)
                            st.info("Kamada-Kawaiå¸ƒå±€è®¡ç®—å¤±è´¥ï¼Œå·²åˆ‡æ¢åˆ°Springå¸ƒå±€")
                    elif layout_name == "fruchterman_reingold":
                        pos = nx.fruchterman_reingold_layout(G, k=2, iterations=100, seed=42)
                    elif layout_name == "circular":
                        pos = nx.circular_layout(G)
                    elif layout_name == "shell":
                        # æŒ‰åº¦æ•°åˆ†å±‚
                        degrees = dict(G.degree())
                        if degrees:
                            max_deg = max(degrees.values())
                            shells = [[] for _ in range(min(5, max_deg + 1))]
                            for node, deg in degrees.items():
                                shell_idx = min(deg * 4 // (max_deg + 1), len(shells) - 1)
                                shells[shell_idx].append(node)
                            shells = [s for s in shells if s]  # ç§»é™¤ç©ºå±‚
                            if shells:
                                pos = nx.shell_layout(G, nlist=shells)
                            else:
                                pos = nx.shell_layout(G)
                        else:
                            pos = nx.shell_layout(G)
                    elif layout_name == "spectral":
                        try:
                            pos = nx.spectral_layout(G)
                        except:
                            pos = nx.spring_layout(G, k=2, iterations=100, seed=42)
                            st.info("è°±å¸ƒå±€è®¡ç®—å¤±è´¥ï¼Œå·²åˆ‡æ¢åˆ°Springå¸ƒå±€")
                    elif layout_name == "random":
                        pos = nx.random_layout(G, seed=42)
                    elif layout_name == "spiral":
                        pos = nx.spiral_layout(G)
                    else:
                        pos = nx.spring_layout(G, k=2, iterations=100, seed=42)
                    
                    # é…è‰²æ–¹æ¡ˆå®šä¹‰
                    color_schemes = {
                        "å­¦æœ¯è“": {
                            "node_colorscale": [[0, "#E3F2FD"], [0.5, "#2196F3"], [1, "#0D47A1"]],
                            "edge_color": "#90A4AE",
                            "bg_color": "white" if not transparent_bg else "rgba(0,0,0,0)",
                            "font_color": "#263238",
                            "community_colors": ["#1976D2", "#388E3C", "#F57C00", "#7B1FA2", "#C2185B", "#00796B", "#5D4037", "#455A64"]
                        },
                        "ç»å…¸ç°": {
                            "node_colorscale": [[0, "#ECEFF1"], [0.5, "#607D8B"], [1, "#263238"]],
                            "edge_color": "#B0BEC5",
                            "bg_color": "white" if not transparent_bg else "rgba(0,0,0,0)",
                            "font_color": "#37474F",
                            "community_colors": ["#37474F", "#546E7A", "#78909C", "#90A4AE", "#B0BEC5", "#CFD8DC", "#455A64", "#263238"]
                        },
                        "æš–è‰²è°ƒ": {
                            "node_colorscale": [[0, "#FFF3E0"], [0.5, "#FF9800"], [1, "#E65100"]],
                            "edge_color": "#FFCC80",
                            "bg_color": "white" if not transparent_bg else "rgba(0,0,0,0)",
                            "font_color": "#BF360C",
                            "community_colors": ["#E65100", "#F57C00", "#FF9800", "#FFA726", "#FFB74D", "#FFCC80", "#D84315", "#BF360C"]
                        },
                        "å†·è‰²è°ƒ": {
                            "node_colorscale": [[0, "#E8F5E9"], [0.5, "#4CAF50"], [1, "#1B5E20"]],
                            "edge_color": "#A5D6A7",
                            "bg_color": "white" if not transparent_bg else "rgba(0,0,0,0)",
                            "font_color": "#1B5E20",
                            "community_colors": ["#1B5E20", "#2E7D32", "#388E3C", "#43A047", "#4CAF50", "#66BB6A", "#81C784", "#A5D6A7"]
                        },
                        "å½©è™¹": {
                            "node_colorscale": "Viridis",
                            "edge_color": "#9E9E9E",
                            "bg_color": "white" if not transparent_bg else "rgba(0,0,0,0)",
                            "font_color": "#424242",
                            "community_colors": ["#E91E63", "#9C27B0", "#673AB7", "#3F51B5", "#2196F3", "#00BCD4", "#4CAF50", "#FFEB3B"]
                        },
                        "é»‘ç™½æ‰“å°": {
                            "node_colorscale": [[0, "#E0E0E0"], [0.5, "#757575"], [1, "#212121"]],
                            "edge_color": "#9E9E9E",
                            "bg_color": "white" if not transparent_bg else "rgba(0,0,0,0)",
                            "font_color": "#212121",
                            "community_colors": ["#212121", "#424242", "#616161", "#757575", "#9E9E9E", "#BDBDBD", "#E0E0E0", "#F5F5F5"]
                        }
                    }
                    
                    scheme = color_schemes.get(color_scheme, color_schemes["å­¦æœ¯è“"])
                    
                    # ç¤¾åŒºæ£€æµ‹
                    community_labels = {}
                    num_communities = 0
                    if enable_community:
                        try:
                            from networkx.algorithms import community as nx_community
                            communities = nx_community.louvain_communities(G, resolution=community_resolution, seed=42)
                            for idx, comm in enumerate(communities):
                                for node in comm:
                                    community_labels[node] = idx
                            num_communities = len(communities)
                        except Exception as e:
                            st.warning(f"ç¤¾åŒºæ£€æµ‹å¤±è´¥: {e}")
                            enable_community = False
                    
                    # è®¡ç®—èŠ‚ç‚¹åº¦æ•°å’Œæƒé‡
                    node_degrees = dict(G.degree())
                    max_degree = max(node_degrees.values()) if node_degrees else 1
                    
                    # è®¡ç®—èŠ‚ç‚¹æ€»æƒé‡
                    node_weights = {}
                    for node in G.nodes():
                        node_weights[node] = sum(G[node][neighbor]['weight'] for neighbor in G.neighbors(node))
                    max_node_weight = max(node_weights.values()) if node_weights else 1
                    
                    # è®¡ç®—è¾¹æƒé‡èŒƒå›´
                    edge_weights = [G[u][v]['weight'] for u, v in G.edges()]
                    max_weight = max(edge_weights) if edge_weights else 1
                    min_weight = min(edge_weights) if edge_weights else 1
                    
                    # è¾¹çº¿æ ·å¼æ˜ å°„
                    edge_dash_map = {
                        "å®çº¿": "solid",
                        "è™šçº¿": "dash",
                        "ç‚¹çº¿": "dot"
                    }
                    edge_dash = edge_dash_map.get(edge_style, "solid")
                    
                    # åˆ›å»ºè¾¹çš„è½¨è¿¹ï¼ˆæ ¹æ®æƒé‡è°ƒæ•´ç²—ç»†ï¼‰
                    edge_traces = []
                    edge_annotations = []
                    
                    for edge in G.edges(data=True):
                        x0, y0 = pos[edge[0]]
                        x1, y1 = pos[edge[1]]
                        weight = edge[2].get('weight', 1)
                        
                        # æ ¹æ®æƒé‡è®¡ç®—è¾¹çš„ç²—ç»†
                        if edge_width_mode == "æƒé‡ (å…±ç°é¢‘ç‡)":
                            if max_weight > min_weight:
                                normalized_weight = (weight - min_weight) / (max_weight - min_weight)
                            else:
                                normalized_weight = 0.5
                            edge_width = (0.5 + normalized_weight * 2.5) * edge_width_scale
                        else:
                            edge_width = 1.5 * edge_width_scale
                        
                        # è¾¹é¢œè‰²ï¼ˆè€ƒè™‘é€æ˜åº¦ï¼‰
                        edge_color_with_opacity = scheme["edge_color"]
                        if edge_opacity < 1.0:
                            # è½¬æ¢ä¸ºrgba
                            hex_color = scheme["edge_color"].lstrip('#')
                            r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
                            edge_color_with_opacity = f"rgba({r},{g},{b},{edge_opacity})"
                        
                        edge_trace = go.Scatter(
                            x=[x0, x1, None],
                            y=[y0, y1, None],
                            line=dict(width=edge_width, color=edge_color_with_opacity, dash=edge_dash),
                            hoverinfo='text',
                            hovertext=f"{edge[0]} - {edge[1]}: {weight}",
                            mode='lines',
                            showlegend=False
                        )
                        edge_traces.append(edge_trace)
                        
                        # è¾¹æ ‡ç­¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if show_edge_labels:
                            mid_x = (x0 + x1) / 2
                            mid_y = (y0 + y1) / 2
                            edge_annotations.append(
                                dict(
                                    x=mid_x,
                                    y=mid_y,
                                    text=str(weight),
                                    showarrow=False,
                                    font=dict(size=font_size - 2, color=scheme["font_color"]),
                                    bgcolor="rgba(255,255,255,0.7)"
                                )
                            )
                    
                    # èŠ‚ç‚¹å½¢çŠ¶æ˜ å°„
                    node_symbol_map = {
                        "åœ†å½¢": "circle",
                        "æ–¹å½¢": "square",
                        "è±å½¢": "diamond",
                        "ä¸‰è§’å½¢": "triangle-up"
                    }
                    node_symbol = node_symbol_map.get(node_shape, "circle")
                    
                    # æ ‡ç­¾ä½ç½®æ˜ å°„
                    label_pos_map = {
                        "ä¸Šæ–¹": "top center",
                        "ä¸‹æ–¹": "bottom center",
                        "å³ä¾§": "middle right",
                        "å·¦ä¾§": "middle left",
                        "å±…ä¸­": "middle center"
                    }
                    text_position = label_pos_map.get(label_position, "top center")
                    
                    # åˆ›å»ºèŠ‚ç‚¹çš„è½¨è¿¹
                    node_x = []
                    node_y = []
                    node_text = []
                    node_hover = []
                    node_size = []
                    node_color = []
                    
                    for node in G.nodes():
                        x, y = pos[node]
                        node_x.append(x)
                        node_y.append(y)
                        node_text.append(node if show_node_labels else "")
                        
                        degree = node_degrees[node]
                        total_weight = node_weights[node]
                        
                        # æ‚¬åœä¿¡æ¯
                        hover_text = f"{node}<br>è¿æ¥æ•°: {degree}<br>æ€»å…±ç°é¢‘ç‡: {total_weight}"
                        if enable_community and node in community_labels:
                            hover_text += f"<br>ç¤¾åŒº: {community_labels[node] + 1}"
                        node_hover.append(hover_text)
                        
                        # èŠ‚ç‚¹å¤§å°
                        if node_size_mode == "åº¦æ•° (è¿æ¥æ•°)":
                            base_size = 15 + (degree / max_degree) * 35
                        elif node_size_mode == "æƒé‡ (å…±ç°æ€»é¢‘ç‡)":
                            base_size = 15 + (total_weight / max_node_weight) * 35
                        else:  # ç»Ÿä¸€å¤§å°
                            base_size = 25
                        node_size.append(base_size * node_size_scale)
                        
                        # èŠ‚ç‚¹é¢œè‰²
                        if enable_community and node in community_labels:
                            node_color.append(community_labels[node])
                        else:
                            node_color.append(degree)
                    
                    # ç¡®å®šèŠ‚ç‚¹é¢œè‰²æ–¹æ¡ˆ
                    if enable_community and num_communities > 0:
                        # ä½¿ç”¨ç¤¾åŒºé¢œè‰²
                        community_color_list = scheme["community_colors"]
                        node_colors_final = [community_color_list[c % len(community_color_list)] for c in node_color]
                        colorbar_config = None  # ç¤¾åŒºæ¨¡å¼ä¸æ˜¾ç¤ºè¿ç»­è‰²æ¡
                        use_discrete_colors = True
                    else:
                        node_colors_final = node_color
                        colorbar_config = dict(
                            thickness=15,
                            title=dict(
                                text='è¿æ¥æ•°' if node_size_mode == "åº¦æ•° (è¿æ¥æ•°)" else 'å…±ç°é¢‘ç‡',
                                font=dict(size=12, family="SimHei, Arial")
                            ),
                            xanchor='left',
                            tickfont=dict(size=10)
                        ) if show_colorbar else None
                        use_discrete_colors = False
                    
                    node_trace = go.Scatter(
                        x=node_x,
                        y=node_y,
                        mode='markers+text' if show_node_labels else 'markers',
                        hoverinfo='text',
                        hovertext=node_hover,
                        text=node_text,
                        textposition=text_position,
                        textfont=dict(
                            size=font_size,
                            color=scheme["font_color"],
                            family="SimHei, Arial, sans-serif"
                        ),
                        marker=dict(
                            showscale=show_colorbar and not use_discrete_colors,
                            colorscale=scheme["node_colorscale"] if not use_discrete_colors else None,
                            size=node_size,
                            color=node_colors_final,
                            colorbar=colorbar_config,
                            symbol=node_symbol,
                            opacity=node_opacity,
                            line=dict(width=1.5, color='white')
                        )
                    )
                    
                    # åˆ›å»ºå›¾å½¢
                    annotations_list = edge_annotations if show_edge_labels else []
                    
                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ³¨é‡Š
                    if show_stats_annotation:
                        stats_text = f"èŠ‚ç‚¹æ•°: {len(nodes)} | è¾¹æ•°: {len(edges)} | å¸ƒå±€: {layout_name}"
                        if enable_community and num_communities > 0:
                            stats_text += f" | ç¤¾åŒºæ•°: {num_communities}"
                        annotations_list.append(
                            dict(
                                text=stats_text,
                                xref="paper", yref="paper",
                                x=0, y=-0.02,
                                showarrow=False,
                                font=dict(size=10, color=scheme["font_color"]),
                                align="left"
                            )
                        )
                    
                    fig = go.Figure(
                        data=edge_traces + [node_trace],
                        layout=go.Layout(
                            title=dict(
                                text=custom_title if show_title else "",
                                font=dict(size=16, family="SimHei, Arial", color=scheme["font_color"]),
                                x=0.5,
                                xanchor='center'
                            ) if show_title else None,
                            showlegend=False,
                            hovermode='closest',
                            xaxis=dict(
                                showgrid=False,
                                zeroline=False,
                                showticklabels=False,
                                showline=False
                            ),
                            yaxis=dict(
                                showgrid=False,
                                zeroline=False,
                                showticklabels=False,
                                showline=False
                            ),
                            plot_bgcolor=scheme["bg_color"],
                            paper_bgcolor=scheme["bg_color"],
                            height=700,
                            margin=dict(l=20, r=20, t=50 if show_title else 20, b=40 if show_stats_annotation else 20),
                            annotations=annotations_list
                        )
                    )
                    
                    # å¦‚æœå¯ç”¨ç¤¾åŒºæ£€æµ‹ï¼Œæ·»åŠ ç¤¾åŒºå›¾ä¾‹
                    if enable_community and num_communities > 0:
                        for i in range(min(num_communities, 8)):
                            fig.add_trace(go.Scatter(
                                x=[None], y=[None],
                                mode='markers',
                                marker=dict(size=10, color=scheme["community_colors"][i]),
                                name=f'ç¤¾åŒº {i+1}',
                                showlegend=True
                            ))
                        fig.update_layout(
                            showlegend=True,
                            legend=dict(
                                title="ç¤¾åŒº",
                                orientation="v",
                                yanchor="top",
                                y=0.99,
                                xanchor="left",
                                x=1.02,
                                font=dict(size=10)
                            )
                        )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # æ˜¾ç¤ºç½‘ç»œç»Ÿè®¡
                    st.markdown("---")
                    st.markdown("**ğŸ“Š ç½‘ç»œç»Ÿè®¡æŒ‡æ ‡**")
                    
                    # åŸºç¡€æŒ‡æ ‡
                    avg_degree = sum(node_degrees.values()) / len(node_degrees) if node_degrees else 0
                    density = nx.density(G)
                    
                    stat_row1 = st.columns(4)
                    stat_row1[0].metric("èŠ‚ç‚¹æ•°", len(nodes))
                    stat_row1[1].metric("è¾¹æ•°", len(edges))
                    stat_row1[2].metric("å¹³å‡åº¦æ•°", f"{avg_degree:.2f}")
                    stat_row1[3].metric("ç½‘ç»œå¯†åº¦", f"{density:.4f}")
                    
                    # é«˜çº§æŒ‡æ ‡ï¼ˆå¯å±•å¼€ï¼‰
                    with st.expander("ğŸ”¬ é«˜çº§ç½‘ç»œæŒ‡æ ‡", expanded=False):
                        try:
                            # è®¡ç®—æ›´å¤šç½‘ç»œæŒ‡æ ‡
                            adv_col1, adv_col2 = st.columns(2)
                            
                            with adv_col1:
                                st.markdown("**ä¸­å¿ƒæ€§æŒ‡æ ‡**")
                                
                                # åº¦ä¸­å¿ƒæ€§
                                degree_centrality = nx.degree_centrality(G)
                                top_degree = sorted(degree_centrality.items(), key=lambda x: -x[1])[:5]
                                st.markdown("åº¦ä¸­å¿ƒæ€§ Top 5:")
                                for word, cent in top_degree:
                                    st.markdown(f"- {word}: {cent:.4f}")
                                
                                # ä»‹æ•°ä¸­å¿ƒæ€§
                                if len(G.nodes()) <= 100:  # å¤§ç½‘ç»œè®¡ç®—è¾ƒæ…¢
                                    betweenness = nx.betweenness_centrality(G)
                                    top_between = sorted(betweenness.items(), key=lambda x: -x[1])[:5]
                                    st.markdown("ä»‹æ•°ä¸­å¿ƒæ€§ Top 5:")
                                    for word, cent in top_between:
                                        st.markdown(f"- {word}: {cent:.4f}")
                            
                            with adv_col2:
                                st.markdown("**ç½‘ç»œç»“æ„æŒ‡æ ‡**")
                                
                                # èšç±»ç³»æ•°
                                avg_clustering = nx.average_clustering(G)
                                st.markdown(f"å¹³å‡èšç±»ç³»æ•°: {avg_clustering:.4f}")
                                
                                # è¿é€šåˆ†é‡
                                num_components = nx.number_connected_components(G)
                                st.markdown(f"è¿é€šåˆ†é‡æ•°: {num_components}")
                                
                                # æœ€å¤§è¿é€šåˆ†é‡å¤§å°
                                if num_components > 0:
                                    largest_cc = max(nx.connected_components(G), key=len)
                                    st.markdown(f"æœ€å¤§è¿é€šåˆ†é‡èŠ‚ç‚¹æ•°: {len(largest_cc)}")
                                
                                # ç¤¾åŒºæ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                                if enable_community and num_communities > 0:
                                    st.markdown(f"æ£€æµ‹åˆ°çš„ç¤¾åŒºæ•°: {num_communities}")
                                    
                                    # æ¨¡å—åº¦
                                    try:
                                        from networkx.algorithms import community as nx_community
                                        communities_list = list(nx_community.louvain_communities(G, resolution=community_resolution, seed=42))
                                        modularity = nx_community.modularity(G, communities_list)
                                        st.markdown(f"æ¨¡å—åº¦ (Modularity): {modularity:.4f}")
                                    except:
                                        pass
                        
                        except Exception as e:
                            st.warning(f"éƒ¨åˆ†é«˜çº§æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
                    
                    # å¯¼å‡ºé«˜åˆ†è¾¨ç‡å›¾ç‰‡
                    st.markdown("---")
                    st.markdown("**ğŸ“¥ å¯¼å‡ºé«˜åˆ†è¾¨ç‡å›¾ç‰‡**")
                    export_col1, export_col2, export_col3 = st.columns(3)
                    
                    with export_col1:
                        export_format = st.selectbox(
                            "å¯¼å‡ºæ ¼å¼",
                            ["PNG (æ¨è)", "SVG (çŸ¢é‡å›¾)", "PDF"],
                            help="PNGé€‚åˆä¸€èˆ¬ç”¨é€”ï¼ŒSVGé€‚åˆéœ€è¦ç¼©æ”¾çš„åœºæ™¯ï¼ŒPDFé€‚åˆç›´æ¥æ’å…¥è®ºæ–‡"
                        )
                    
                    with export_col2:
                        export_dpi = st.selectbox(
                            "åˆ†è¾¨ç‡ (DPI)",
                            [150, 300, 600],
                            index=1,
                            help="300 DPIé€‚åˆå¤§å¤šæ•°å­¦æœ¯æœŸåˆŠè¦æ±‚"
                        )
                    
                    with export_col3:
                        export_size = st.selectbox(
                            "å›¾ç‰‡å°ºå¯¸",
                            ["æ ‡å‡† (1200Ã—900)", "å¤§ (1600Ã—1200)", "è¶…å¤§ (2400Ã—1800)"],
                            index=0,
                            help="é€‰æ‹©å¯¼å‡ºå›¾ç‰‡çš„å°ºå¯¸"
                        )
                    
                    if st.button("ğŸ–¼ï¸ ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾ç‰‡", key="export_network_img"):
                        try:
                            import io
                            
                            # è§£æå°ºå¯¸
                            size_map = {
                                "æ ‡å‡† (1200Ã—900)": (1200, 900),
                                "å¤§ (1600Ã—1200)": (1600, 1200),
                                "è¶…å¤§ (2400Ã—1800)": (2400, 1800)
                            }
                            export_width, export_height = size_map.get(export_size, (1200, 900))
                            scale = export_dpi / 72  # 72æ˜¯é»˜è®¤DPI
                            
                            if "PNG" in export_format:
                                img_bytes = fig.to_image(
                                    format="png",
                                    width=export_width,
                                    height=export_height,
                                    scale=scale
                                )
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½ PNG å›¾ç‰‡",
                                    data=img_bytes,
                                    file_name="cooccurrence_network.png",
                                    mime="image/png"
                                )
                            elif "SVG" in export_format:
                                img_bytes = fig.to_image(
                                    format="svg",
                                    width=export_width,
                                    height=export_height
                                )
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½ SVG å›¾ç‰‡",
                                    data=img_bytes,
                                    file_name="cooccurrence_network.svg",
                                    mime="image/svg+xml"
                                )
                            elif "PDF" in export_format:
                                img_bytes = fig.to_image(
                                    format="pdf",
                                    width=export_width,
                                    height=export_height
                                )
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½ PDF æ–‡ä»¶",
                                    data=img_bytes,
                                    file_name="cooccurrence_network.pdf",
                                    mime="application/pdf"
                                )
                            
                            st.success("å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ä¸‹è½½")
                            
                        except Exception as e:
                            st.warning(f"å›¾ç‰‡å¯¼å‡ºéœ€è¦å®‰è£… kaleido åº“: pip install kaleido")
                            st.info("æ‚¨ä¹Ÿå¯ä»¥å³é”®ç‚¹å‡»å›¾è¡¨é€‰æ‹©ã€Œå¦å­˜ä¸ºå›¾ç‰‡ã€")
                    
                except ImportError:
                    st.warning("éœ€è¦å®‰è£…plotlyå’Œnetworkxåº“æ‰èƒ½æ˜¾ç¤ºç½‘ç»œå›¾")
                    st.code("pip install plotly networkx")
            else:
                st.info("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç”Ÿæˆç½‘ç»œå›¾")
        
        # å…±ç°è¡¨æ ¼
        with result_tabs[1]:
            st.subheader("å…±ç°è¯è¯­å¯¹")
            
            # æ’åºå¹¶æ˜¾ç¤º
            sorted_cooc = sorted(cooccurrence.items(), key=lambda x: -x[1])
            
            df = pd.DataFrame([
                {"è¯è¯­1": pair[0], "è¯è¯­2": pair[1], "å…±ç°é¢‘ç‡": freq}
                for pair, freq in sorted_cooc
            ])
            
            st.dataframe(df, use_container_width=True, hide_index=True, height=400)
        
        # è¯è¯­æŸ¥è¯¢
        with result_tabs[2]:
            st.subheader("æŸ¥è¯¢è¯è¯­å…±ç°")
            
            query_word = st.text_input("è¾“å…¥è¦æŸ¥è¯¢çš„è¯è¯­")
            
            if query_word:
                word_cooc = analyzer.get_word_cooccurrences(query_word, min_freq)
                
                if word_cooc:
                    st.success(f"æ‰¾åˆ° {len(word_cooc)} ä¸ªä¸ã€Œ{query_word}ã€å…±ç°çš„è¯è¯­")
                    
                    sorted_cooc = sorted(word_cooc.items(), key=lambda x: -x[1])
                    df = pd.DataFrame(sorted_cooc, columns=["å…±ç°è¯è¯­", "å…±ç°é¢‘ç‡"])
                    st.dataframe(df, use_container_width=True, hide_index=True)
                else:
                    st.info(f"æœªæ‰¾åˆ°ä¸ã€Œ{query_word}ã€å…±ç°çš„è¯è¯­")
        
        # å¯¼å‡º
        with result_tabs[3]:
            st.subheader("å¯¼å‡ºå…±ç°æ•°æ®")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**å…±ç°è¯è¯­å¯¹åˆ—è¡¨**")
                csv_content = analyzer.export_matrix_csv(min_freq)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å…±ç°åˆ—è¡¨CSV",
                    data=csv_content,
                    file_name="cooccurrence_list.csv",
                    mime="text/csv"
                )
            
            with col2:
                st.markdown("**é‚»æ¥çŸ©é˜µæ ¼å¼**")
                adj_csv = analyzer.export_adjacency_matrix_csv(min_freq, max_nodes)
                if adj_csv:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½é‚»æ¥çŸ©é˜µCSV",
                        data=adj_csv,
                        file_name="cooccurrence_matrix.csv",
                        mime="text/csv"
                    )
