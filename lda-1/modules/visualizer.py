import streamlit as st
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
import umap
import networkx as nx
import pyLDAvis
import pyLDAvis.gensim_models
import tempfile
from pathlib import Path
import time
from datetime import datetime
import io
import base64
from utils.session_state import get_session_state, log_message, update_progress

# é…ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

def get_system_font_path():
    """è·å–ç³»ç»Ÿä¸­æ–‡å­—ä½“è·¯å¾„"""
    import platform
    system = platform.system()
    
    # å¸¸è§ä¸­æ–‡å­—ä½“è·¯å¾„
    font_paths = []
    
    if system == "Windows":
        font_paths = [
            r"c:\Windows\Fonts\SimHei.ttf",
            r"c:\Windows\Fonts\msyh.ttc",
            r"c:\Windows\Fonts\simsun.ttc",
        ]
    elif system == "Darwin":  # macOS
        font_paths = [
            "/System/Library/Fonts/PingFang.ttc",
            "/System/Library/Fonts/STHeiti Light.ttc",
            "/Library/Fonts/Arial Unicode.ttf",
        ]
    else:  # Linux
        font_paths = [
            "/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc",
            "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        ]
    
    # æ£€æŸ¥å­—ä½“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    for font_path in font_paths:
        if os.path.exists(font_path):
            return font_path
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›Noneï¼ˆWordCloudä¼šä½¿ç”¨é»˜è®¤å­—ä½“ï¼‰
    return None

class LDAVisualizer:
    """LDAä¸»é¢˜æ¨¡å‹å¯è§†åŒ–ç±»"""
    
    def __init__(self, lda_model, corpus, dictionary, texts, doc_topic_dist=None, file_names=None):
        self.lda_model = lda_model
        self.corpus = corpus
        self.dictionary = dictionary
        self.texts = texts
        self.doc_topic_dist = doc_topic_dist
        self.file_names = file_names if file_names else [f"æ–‡æ¡£{i+1}" for i in range(len(corpus))]
    
    def generate_wordcloud(self, topic_id, max_words=50, width=800, height=400):
        """ä¸ºæŒ‡å®šä¸»é¢˜ç”Ÿæˆè¯äº‘"""
        # è·å–ä¸»é¢˜è¯åˆ†å¸ƒ
        topic_words = dict(self.lda_model.show_topic(topic_id, topn=max_words))
        
        # è®¾ç½®è¯äº‘é¢œè‰²
        colors = [color for name, color in mcolors.TABLEAU_COLORS.items()]
        color = colors[topic_id % len(colors)]
        
        # è·å–ç³»ç»Ÿå­—ä½“è·¯å¾„
        font_path = get_system_font_path()
        
        # ç”Ÿæˆè¯äº‘
        cloud = WordCloud(
            width=width,
            height=height,
            font_path=font_path,  # ä½¿ç”¨åŠ¨æ€æ£€æµ‹çš„å­—ä½“
            background_color='white',
            colormap='tab10',
            color_func=lambda *args, **kwargs: color,
            max_words=max_words,
            max_font_size=300,
            random_state=42
        )
        
        # æ ¹æ®è¯é¢‘ç”Ÿæˆè¯äº‘
        cloud.generate_from_frequencies(topic_words)
        
        return cloud
    
    def generate_doc_topic_heatmap(self, normalize=True):
        """ç”Ÿæˆæ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒçƒ­å›¾æ•°æ®"""
        # è·å–æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒ
        if self.doc_topic_dist is None:
            doc_topic_dist = []
            for i, doc in enumerate(self.corpus):
                # è·å–æ–‡æ¡£çš„ä¸»é¢˜åˆ†å¸ƒ
                topics = self.lda_model.get_document_topics(doc, minimum_probability=0.0)
                doc_topic_dist.append([prob for _, prob in sorted(topics)])
            
            doc_topic_dist = np.array(doc_topic_dist)
        else:
            doc_topic_dist = self.doc_topic_dist
            
        # å½’ä¸€åŒ–
        if normalize and doc_topic_dist.shape[0] > 0:
            doc_topic_dist = doc_topic_dist / doc_topic_dist.sum(axis=1, keepdims=True)
        
        # åˆ›å»ºæ•°æ®æ¡†
        topics = [f"ä¸»é¢˜{i+1}" for i in range(doc_topic_dist.shape[1])]
        
        # ä½¿ç”¨å®é™…æ–‡ä»¶åæˆ–é»˜è®¤åç§°
        df = pd.DataFrame(doc_topic_dist, columns=topics)
        df['æ–‡æ¡£'] = self.file_names[:len(df)]
        
        return df
    
    def generate_pyldavis(self):
        """ç”ŸæˆPyLDAviså¯è§†åŒ–"""
        try:
            # å‡†å¤‡PyLDAvisæ•°æ®
            prepared_data = pyLDAvis.gensim_models.prepare(
                self.lda_model, self.corpus, self.dictionary, sort_topics=False
            )
            
            # è½¬æ¢ä¸ºHTML
            html_string = pyLDAvis.prepared_data_to_html(prepared_data)
            
            return html_string
        except Exception as e:
            log_message(f"ç”ŸæˆPyLDAviså¯è§†åŒ–å¤±è´¥: {str(e)}", level="error")
            return None
    
    def generate_topic_word_dist(self, num_words=20):
        """ç”Ÿæˆä¸»é¢˜è¯åˆ†å¸ƒæ•°æ®"""
        topic_word_data = []
        
        for topic_id in range(self.lda_model.num_topics):
            # è·å–ä¸»é¢˜è¯åŠæ¦‚ç‡
            topic_words = self.lda_model.show_topic(topic_id, topn=num_words)
            
            for word, prob in topic_words:
                topic_word_data.append({
                    'ä¸»é¢˜': f'ä¸»é¢˜{topic_id+1}',
                    'è¯è¯­': word,
                    'æ¦‚ç‡': prob
                })
        
        return pd.DataFrame(topic_word_data)
    
    def generate_doc_clusters(self, method='tsne', n_clusters=None):
        """ç”Ÿæˆæ–‡æ¡£èšç±»å¯è§†åŒ–æ•°æ®"""
        # è·å–æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒ
        if self.doc_topic_dist is None:
            doc_topic_dist = []
            for i, doc in enumerate(self.corpus):
                topics = self.lda_model.get_document_topics(doc, minimum_probability=0.0)
                doc_topic_dist.append([prob for _, prob in sorted(topics)])
            
            doc_topic_dist = np.array(doc_topic_dist)
        else:
            doc_topic_dist = self.doc_topic_dist
        
        # å¦‚æœæœªæŒ‡å®šèšç±»æ•°ï¼Œä½¿ç”¨ä¸»é¢˜æ•°
        if n_clusters is None:
            n_clusters = self.lda_model.num_topics
        
        # æ‰§è¡Œé™ç»´
        if method.lower() == 'tsne':
            reducer = TSNE(n_components=2, random_state=42, perplexity=min(30, max(5, len(doc_topic_dist)-1)))
            embedding = reducer.fit_transform(doc_topic_dist)
        elif method.lower() == 'umap':
            reducer = umap.UMAP(n_components=2, random_state=42, min_dist=0.1, n_neighbors=min(15, max(2, len(doc_topic_dist)-1)))
            embedding = reducer.fit_transform(doc_topic_dist)
        
        # æ‰§è¡Œèšç±»
        if len(doc_topic_dist) >= n_clusters:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(doc_topic_dist)
        else:
            # å¦‚æœæ–‡æ¡£æ•°å°‘äºèšç±»æ•°ï¼Œç›´æ¥ä½¿ç”¨æ–‡æ¡£çš„ä¸»è¦ä¸»é¢˜ä½œä¸ºèšç±»
            clusters = np.argmax(doc_topic_dist, axis=1)
        
        # è·å–æ¯ä¸ªæ–‡æ¡£çš„ä¸»å¯¼ä¸»é¢˜
        dominant_topics = np.argmax(doc_topic_dist, axis=1)
        
        # åˆ›å»ºæ•°æ®æ¡†
        df = pd.DataFrame({
            'x': embedding[:, 0],
            'y': embedding[:, 1],
            'èšç±»': [f'èšç±»{i+1}' for i in clusters],
            'ä¸»å¯¼ä¸»é¢˜': [f'ä¸»é¢˜{i+1}' for i in dominant_topics],
            'æ–‡æ¡£': self.file_names[:len(doc_topic_dist)]
        })
        
        return df
    
    def generate_topic_similarity_network(self, threshold=0.2):
        """ç”Ÿæˆä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ"""
        num_topics = self.lda_model.num_topics
        
        # è®¡ç®—ä¸»é¢˜ä¹‹é—´çš„ç›¸ä¼¼åº¦çŸ©é˜µ
        topic_vectors = []
        for i in range(num_topics):
            topic_vector = [0] * len(self.dictionary)
            for word_id, weight in self.lda_model.get_topic_terms(i, topn=len(self.dictionary)):
                topic_vector[word_id] = weight
            topic_vectors.append(topic_vector)
        
        topic_vectors = np.array(topic_vectors)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity_matrix = np.zeros((num_topics, num_topics))
        for i in range(num_topics):
            for j in range(num_topics):
                # é¿å…è‡ªå·±ä¸è‡ªå·±æ¯”è¾ƒ
                if i == j:
                    similarity_matrix[i, j] = 1.0
                else:
                    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                    dot_product = np.dot(topic_vectors[i], topic_vectors[j])
                    norm_i = np.linalg.norm(topic_vectors[i])
                    norm_j = np.linalg.norm(topic_vectors[j])
                    
                    if norm_i > 0 and norm_j > 0:
                        similarity_matrix[i, j] = dot_product / (norm_i * norm_j)
                    else:
                        similarity_matrix[i, j] = 0
        
        # åˆ›å»ºç½‘ç»œå›¾
        G = nx.Graph()
        
        # æ·»åŠ èŠ‚ç‚¹
        for i in range(num_topics):
            G.add_node(i, name=f"ä¸»é¢˜{i+1}")
        
        # æ·»åŠ è¾¹ï¼ˆåªæ·»åŠ è¶…è¿‡é˜ˆå€¼çš„ç›¸ä¼¼åº¦ï¼‰
        for i in range(num_topics):
            for j in range(i+1, num_topics):
                if similarity_matrix[i, j] >= threshold:
                    G.add_edge(i, j, weight=similarity_matrix[i, j])
        
        return G, similarity_matrix

def render_visualizer():
    """æ¸²æŸ“å¯è§†åŒ–åˆ†ææ¨¡å—"""
    st.header("å¯è§†åŒ–åˆ†æ")
    
    # åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ
    with st.expander("ğŸ“– åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ", expanded=False):
        st.markdown("""
        ## ğŸ“Š å¯è§†åŒ–åˆ†ææ¨¡å—
        
        **åŠŸèƒ½æ¦‚è¿°**ï¼šæä¾›å¤šç§å›¾è¡¨å±•ç¤ºLDAä¸»é¢˜æ¨¡å‹çš„åˆ†æç»“æœï¼Œå¸®åŠ©ç†è§£å’Œè§£é‡Šä¸»é¢˜ç»“æ„ã€‚
        
        ---
        
        ### ğŸ¯ ä½¿ç”¨åœºæ™¯
        
        | å¯è§†åŒ–ç±»å‹ | é€‚ç”¨åœºæ™¯ | è¾“å‡ºç”¨é€” |
        |------------|----------|----------|
        | ä¸»é¢˜è¯äº‘ | å¿«é€Ÿäº†è§£ä¸»é¢˜å†…å®¹ | è®ºæ–‡é…å›¾ã€æŠ¥å‘Šå±•ç¤º |
        | æ–‡æ¡£-ä¸»é¢˜çƒ­å›¾ | åˆ†ææ–‡æ¡£å½’å± | æ•°æ®åˆ†æã€åˆ†ç±»ä¾æ® |
        | PyLDAvis | æ·±å…¥æ¢ç´¢ä¸»é¢˜ç»“æ„ | äº¤äº’å¼åˆ†æã€æ¼”ç¤º |
        | æ–‡æ¡£èšç±» | å‘ç°æ–‡æ¡£åˆ†å¸ƒè§„å¾‹ | èšç±»åˆ†æã€å¼‚å¸¸æ£€æµ‹ |
        | ä¸»é¢˜è¯åˆ†å¸ƒ | æ¯”è¾ƒä¸»é¢˜å·®å¼‚ | ä¸»é¢˜è§£é‡Šã€è®ºæ–‡é…å›¾ |
        | ç›¸ä¼¼æ€§ç½‘ç»œ | åˆ†æä¸»é¢˜å…³è” | ä¸»é¢˜å…³ç³»åˆ†æ |
        
        ---
        
        ### ğŸ“‹ å„å¯è§†åŒ–åŠŸèƒ½è¯¦è§£
        
        #### 1ï¸âƒ£ ä¸»é¢˜è¯äº‘
        **åŠŸèƒ½**ï¼šä»¥è¯äº‘å½¢å¼å±•ç¤ºæ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯ï¼Œè¯è¯­å¤§å°è¡¨ç¤ºé‡è¦ç¨‹åº¦ã€‚
        
        **æ“ä½œæ­¥éª¤**ï¼š
        1. é€‰æ‹©è¦æŸ¥çœ‹çš„ä¸»é¢˜ç¼–å·
        2. è°ƒæ•´æœ€å¤§è¯æ•°å’Œè¯äº‘å®½åº¦
        3. ç‚¹å‡»"ç”Ÿæˆæ‰€æœ‰ä¸»é¢˜çš„è¯äº‘"å¯ä¸€æ¬¡æ€§ç”Ÿæˆå…¨éƒ¨
        
        **å‚æ•°è¯´æ˜**ï¼š
        - æœ€å¤§è¯æ•°ï¼šè¯äº‘ä¸­æ˜¾ç¤ºçš„è¯è¯­æ•°é‡ï¼ˆ10-100ï¼‰
        - è¯äº‘å®½åº¦ï¼šå›¾åƒå®½åº¦ï¼ˆ400-1200åƒç´ ï¼‰
        
        ---
        
        #### 2ï¸âƒ£ æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒçƒ­å›¾
        **åŠŸèƒ½**ï¼šå±•ç¤ºæ¯ä¸ªæ–‡æ¡£åœ¨å„ä¸»é¢˜ä¸Šçš„åˆ†å¸ƒæ¯”ä¾‹ï¼Œé¢œè‰²æ·±æµ…è¡¨ç¤ºå…³è”å¼ºåº¦ã€‚
        
        **è§£è¯»æ–¹æ³•**ï¼š
        - é¢œè‰²è¶Šæ·±è¡¨ç¤ºæ–‡æ¡£ä¸è¯¥ä¸»é¢˜å…³è”è¶Šå¼º
        - æ¯è¡Œä»£è¡¨ä¸€ä¸ªæ–‡æ¡£ï¼Œæ¯åˆ—ä»£è¡¨ä¸€ä¸ªä¸»é¢˜
        - å¯ç”¨äºåˆ¤æ–­æ–‡æ¡£çš„ä¸»è¦ä¸»é¢˜å½’å±
        
        ---
        
        #### 3ï¸âƒ£ äº¤äº’å¼PyLDAvis
        **åŠŸèƒ½**ï¼šä¸“ä¸šçš„LDAå¯è§†åŒ–å·¥å…·ï¼Œæä¾›äº¤äº’å¼ä¸»é¢˜æ¢ç´¢ã€‚
        
        **ç•Œé¢è¯´æ˜**ï¼š
        - **å·¦ä¾§æ°”æ³¡å›¾**ï¼šæ¯ä¸ªæ°”æ³¡ä»£è¡¨ä¸€ä¸ªä¸»é¢˜
          - æ°”æ³¡å¤§å°ï¼šä¸»é¢˜åœ¨è¯­æ–™åº“ä¸­çš„å æ¯”
          - æ°”æ³¡ä½ç½®ï¼šä¸»é¢˜é—´çš„ç›¸ä¼¼åº¦ï¼ˆè·ç¦»è¶Šè¿‘è¶Šç›¸ä¼¼ï¼‰
        - **å³ä¾§æ¡å½¢å›¾**ï¼šé€‰ä¸­ä¸»é¢˜çš„å…³é”®è¯
          - è“è‰²æ¡ï¼šè¯è¯­åœ¨æ•´ä¸ªè¯­æ–™åº“ä¸­çš„é¢‘ç‡
          - çº¢è‰²æ¡ï¼šè¯è¯­åœ¨é€‰ä¸­ä¸»é¢˜ä¸­çš„é¢‘ç‡
        
        **äº¤äº’æ“ä½œ**ï¼š
        - ç‚¹å‡»æ°”æ³¡é€‰æ‹©ä¸»é¢˜
        - è°ƒæ•´Î»æ»‘å—æ”¹å˜è¯è¯­æ’åºæ–¹å¼
        - æ‚¬åœæŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
        
        ---
        
        #### 4ï¸âƒ£ æ–‡æ¡£èšç±»
        **åŠŸèƒ½**ï¼šä½¿ç”¨é™ç»´ç®—æ³•å°†æ–‡æ¡£æ˜ å°„åˆ°äºŒç»´ç©ºé—´ï¼Œå±•ç¤ºæ–‡æ¡£åˆ†å¸ƒã€‚
        
        **é™ç»´ç®—æ³•**ï¼š
        - **t-SNE**ï¼šä¿æŒå±€éƒ¨ç»“æ„ï¼Œé€‚åˆå‘ç°èšç±»
        - **UMAP**ï¼šä¿æŒå…¨å±€ç»“æ„ï¼Œè®¡ç®—æ›´å¿«
        
        **å‚æ•°è¯´æ˜**ï¼š
        - èšç±»æ•°é‡ï¼šK-meansèšç±»çš„ç°‡æ•°ï¼ˆå»ºè®®ä¸ä¸»é¢˜æ•°ç›¸åŒï¼‰
        
        ---
        
        #### 5ï¸âƒ£ ä¸»é¢˜è¯åˆ†å¸ƒ
        **åŠŸèƒ½**ï¼šæ¡å½¢å›¾å±•ç¤ºæ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯æ¦‚ç‡åˆ†å¸ƒã€‚
        
        **å‚æ•°è¯´æ˜**ï¼š
        - æ¯ä¸ªä¸»é¢˜æ˜¾ç¤ºè¯æ•°ï¼š5-30ä¸ªè¯
        
        ---
        
        #### 6ï¸âƒ£ ä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ
        **åŠŸèƒ½**ï¼šç½‘ç»œå›¾å±•ç¤ºä¸»é¢˜ä¹‹é—´çš„ç›¸ä¼¼å…³ç³»ã€‚
        
        **å‚æ•°è¯´æ˜**ï¼š
        - ç›¸ä¼¼åº¦é˜ˆå€¼ï¼šåªæ˜¾ç¤ºç›¸ä¼¼åº¦é«˜äºæ­¤å€¼çš„è¿æ¥ï¼ˆ0.1-0.9ï¼‰
        
        **è§£è¯»æ–¹æ³•**ï¼š
        - èŠ‚ç‚¹ä»£è¡¨ä¸»é¢˜
        - è¿çº¿è¡¨ç¤ºä¸»é¢˜é—´å­˜åœ¨ç›¸ä¼¼æ€§
        - èŠ‚ç‚¹é¢œè‰²æ·±æµ…è¡¨ç¤ºè¿æ¥æ•°é‡
        
        ---
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè®®
        
        **åˆ†ææµç¨‹å»ºè®®**ï¼š
        1. å…ˆæŸ¥çœ‹PyLDAvisè·å¾—æ•´ä½“å°è±¡
        2. é€šè¿‡è¯äº‘å’Œè¯åˆ†å¸ƒæ·±å…¥äº†è§£å„ä¸»é¢˜å†…å®¹
        3. ç”¨æ–‡æ¡£èšç±»åˆ†ææ–‡æ¡£åˆ†å¸ƒæƒ…å†µ
        4. ç”¨ç›¸ä¼¼æ€§ç½‘ç»œåˆ†æä¸»é¢˜å…³è”
        
        **è®ºæ–‡é…å›¾å»ºè®®**ï¼š
        - è¯äº‘å›¾ï¼šé€‚åˆå±•ç¤ºä¸»é¢˜å†…å®¹
        - çƒ­å›¾ï¼šé€‚åˆå±•ç¤ºæ–‡æ¡£åˆ†ç±»ç»“æœ
        - èšç±»å›¾ï¼šé€‚åˆå±•ç¤ºæ–‡æ¡£åˆ†å¸ƒ
        
        **å›¾åƒä¿å­˜**ï¼š
        - æ¯ä¸ªå¯è§†åŒ–éƒ½æä¾›ä¿å­˜æŒ‰é’®
        - HTMLæ ¼å¼æ”¯æŒäº¤äº’ï¼Œé€‚åˆæ¼”ç¤º
        - PNGæ ¼å¼é€‚åˆè®ºæ–‡é…å›¾
        
        ---
        
        ### â“ å¸¸è§é—®é¢˜
        
        **Q: PyLDAvisåŠ è½½å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ**
        A: PyLDAviséœ€è¦è®¡ç®—å¤§é‡æ•°æ®ï¼Œé¦–æ¬¡åŠ è½½è¾ƒæ…¢ï¼Œä¹‹åä¼šä½¿ç”¨ç¼“å­˜ã€‚
        
        **Q: è¯äº‘ä¸­æ–‡æ˜¾ç¤ºä¹±ç æ€ä¹ˆåŠï¼Ÿ**
        A: ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ä¸­æ–‡å­—ä½“ï¼Œå¦‚ä»æœ‰é—®é¢˜è¯·ç¡®ä¿ç³»ç»Ÿå®‰è£…äº†ä¸­æ–‡å­—ä½“ã€‚
        
        **Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„èšç±»æ•°é‡ï¼Ÿ**
        A: å»ºè®®ä¸LDAä¸»é¢˜æ•°ç›¸åŒï¼Œæˆ–æ ¹æ®è½®å»“ç³»æ•°é€‰æ‹©æœ€ä¼˜å€¼ã€‚
        """)
    
    # æ£€æŸ¥æ˜¯å¦å®Œæˆäº†æ¨¡å‹è®­ç»ƒ
    if not st.session_state.training_complete or not st.session_state.lda_model:
        st.warning('è¯·å…ˆåœ¨"æ¨¡å‹è®­ç»ƒ"é€‰é¡¹å¡ä¸­å®ŒæˆLDAæ¨¡å‹è®­ç»ƒ')
        return
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç¼“å­˜ï¼ˆå½“æ¨¡å‹æ›´æ–°æ—¶ï¼‰
    current_model_id = id(st.session_state.lda_model)
    if 'last_model_id' not in st.session_state or st.session_state.last_model_id != current_model_id:
        # æ¸…ç†å¯è§†åŒ–ç¼“å­˜
        st.session_state.pyldavis_html = None
        st.session_state.wordcloud_images = {}
        # æ¸…ç†èšç±»ç¼“å­˜
        keys_to_remove = [k for k in st.session_state.keys() if k.startswith('tsne_') or k.startswith('umap_')]
        for key in keys_to_remove:
            del st.session_state[key]
        st.session_state.last_model_id = current_model_id
        log_message("æ£€æµ‹åˆ°æ–°æ¨¡å‹ï¼Œå·²æ¸…ç†å¯è§†åŒ–ç¼“å­˜", level="info")
    
    # é»˜è®¤å¯ç”¨æ‰€æœ‰å¯è§†åŒ–é€‰é¡¹
    for key in st.session_state.viz_options:
        st.session_state.viz_options[key] = True
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = LDAVisualizer(
        st.session_state.lda_model,
        st.session_state.corpus,
        st.session_state.dictionary,
        st.session_state.texts,
        st.session_state.doc_topic_dist,
        st.session_state.file_names
    )
    
    # å¯è§†åŒ–é€‰é¡¹
    st.subheader("å¯è§†åŒ–ç»“æœ")
    
    # åˆ›å»ºé€‰é¡¹å¡
    viz_tabs = st.tabs([
        "ä¸»é¢˜è¯äº‘", 
        "æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒ", 
        "äº¤äº’å¼PyLDAvis", 
        "æ–‡æ¡£èšç±»", 
        "ä¸»é¢˜è¯åˆ†å¸ƒ", 
        "ä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ"
    ])
    
    # ä¸»é¢˜è¯äº‘é€‰é¡¹å¡
    with viz_tabs[0]:
        # ç§»é™¤æ¡ä»¶åˆ¤æ–­ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
        st.subheader("ä¸»é¢˜è¯äº‘")
        
        # è·å–æ¨¡å‹å®é™…çš„ä¸»é¢˜æ•°é‡
        actual_num_topics = st.session_state.lda_model.num_topics if st.session_state.lda_model else st.session_state.num_topics
        
        # é€‰æ‹©è¦æŸ¥çœ‹çš„ä¸»é¢˜
        topic_id = st.selectbox(
            "é€‰æ‹©ä¸»é¢˜",
            range(actual_num_topics),
            format_func=lambda x: f"ä¸»é¢˜ {x+1}",
            key="wordcloud_topic_select"
        )
        
        # è¯äº‘å‚æ•°
        col1, col2 = st.columns(2)
        with col1:
            max_words = st.slider("æœ€å¤§è¯æ•°", 10, 100, 50, key="wordcloud_max_words")
        with col2:
            width = st.slider("è¯äº‘å®½åº¦", 400, 1200, 800, key="wordcloud_width")
        
        # ç”Ÿæˆå¹¶æ˜¾ç¤ºè¯äº‘
        with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"wordcloud_{topic_id}_{max_words}_{width}"
            if cache_key not in st.session_state.wordcloud_images:
                # ç”Ÿæˆè¯äº‘
                wordcloud = visualizer.generate_wordcloud(
                    topic_id=topic_id,
                    max_words=max_words,
                    width=width,
                    height=400
                )
                
                # å°†è¯äº‘è½¬æ¢ä¸ºå›¾åƒ
                fig, ax = plt.subplots(figsize=(width/100, 400/100))
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis("off")
                
                # ç¼“å­˜å›¾åƒ
                st.session_state.wordcloud_images[cache_key] = fig
            
            # æ˜¾ç¤ºè¯äº‘
            st.pyplot(st.session_state.wordcloud_images[cache_key])
        
        # ç”Ÿæˆæ‰€æœ‰ä¸»é¢˜çš„è¯äº‘æŒ‰é’®
        if st.button("ç”Ÿæˆæ‰€æœ‰ä¸»é¢˜çš„è¯äº‘", key="gen_all_wordclouds"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ‰€æœ‰ä¸»é¢˜çš„è¯äº‘..."):
                # åˆ›å»ºå›¾è¡¨ï¼ˆä½¿ç”¨å®é™…ä¸»é¢˜æ•°ï¼‰
                n_topics = actual_num_topics
                n_cols = min(3, n_topics)
                n_rows = (n_topics + n_cols - 1) // n_cols  # å‘ä¸Šå–æ•´
                
                fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
                
                # æ‰å¹³åŒ–è½´æ•°ç»„ä»¥ä¾¿ç´¢å¼•
                if n_rows > 1 and n_cols > 1:
                    axes = axes.flatten()
                elif n_rows == 1 and n_cols > 1:
                    axes = axes
                elif n_rows > 1 and n_cols == 1:
                    axes = [axes[i] for i in range(n_rows)]
                else:
                    axes = [axes]
                
                # ä¸ºæ¯ä¸ªä¸»é¢˜ç”Ÿæˆè¯äº‘
                for i in range(n_topics):
                    # ç”Ÿæˆè¯äº‘
                    wordcloud = visualizer.generate_wordcloud(
                        topic_id=i,
                        max_words=30,
                        width=400,
                        height=300
                    )
                    
                    # åœ¨å­å›¾ä¸­æ˜¾ç¤º
                    axes[i].imshow(wordcloud, interpolation='bilinear')
                    axes[i].set_title(f'ä¸»é¢˜ {i+1}')
                    axes[i].axis("off")
                
                # éšè—ç©ºç™½å­å›¾
                for i in range(n_topics, len(axes)):
                    axes[i].axis("off")
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # ä¿å­˜å›¾åƒ
                save_path = os.path.join("results", f"topic_wordclouds_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                fig.savefig(save_path, dpi=300, bbox_inches='tight')
                st.success(f"å·²ä¿å­˜è¯äº‘å›¾åƒè‡³: {save_path}")
    
    # æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒé€‰é¡¹å¡
    with viz_tabs[1]:
        # ç§»é™¤æ¡ä»¶åˆ¤æ–­ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
        st.subheader("æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒ")
        
        with st.spinner("æ­£åœ¨ç”Ÿæˆæ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒçƒ­å›¾..."):
            # ç”Ÿæˆçƒ­å›¾æ•°æ®
            df = visualizer.generate_doc_topic_heatmap()
            
            # å‡†å¤‡çƒ­å›¾æ•°æ®
            df_melt = df.melt(id_vars='æ–‡æ¡£', var_name='ä¸»é¢˜', value_name='æƒé‡')
            
            # ç»˜åˆ¶çƒ­å›¾
            fig = px.density_heatmap(
                df_melt, 
                x='ä¸»é¢˜', 
                y='æ–‡æ¡£',
                z='æƒé‡',
                color_continuous_scale='Viridis',
                title='æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒçƒ­å›¾'
            )
            
            # è°ƒæ•´å›¾è¡¨å¸ƒå±€
            fig.update_layout(
                width=800,
                height=max(400, len(df) * 30),  # æ ¹æ®æ–‡æ¡£æ•°é‡è°ƒæ•´é«˜åº¦
                xaxis_title='ä¸»é¢˜',
                yaxis_title='æ–‡æ¡£',
                coloraxis_colorbar=dict(title='æƒé‡')
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ä¿å­˜çƒ­å›¾æŒ‰é’®
            if st.button("ä¿å­˜çƒ­å›¾", key="save_heatmap"):
                # ä¿å­˜å›¾åƒ
                save_path = os.path.join("results", f"doc_topic_heatmap_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                fig.write_html(save_path)
                st.success(f"å·²ä¿å­˜çƒ­å›¾è‡³: {save_path}")
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®è¡¨æ ¼
        with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®"):
            st.dataframe(df, use_container_width=True)
            
            # ä¸‹è½½CSVæŒ‰é’®
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ä¸‹è½½CSV",
                data=csv,
                file_name=f"doc_topic_dist_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    
    # äº¤äº’å¼PyLDAvisé€‰é¡¹å¡
    with viz_tabs[2]:
        # ç§»é™¤æ¡ä»¶åˆ¤æ–­ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
        st.subheader("äº¤äº’å¼PyLDAviså¯è§†åŒ–")
        
        # æ£€æŸ¥ç¼“å­˜
        if st.session_state.pyldavis_html is None:
            with st.spinner("æ­£åœ¨ç”ŸæˆPyLDAviså¯è§†åŒ–..."):
                # ç”ŸæˆPyLDAvis
                html_string = visualizer.generate_pyldavis()
                
                if html_string:
                    # ç¼“å­˜HTML
                    st.session_state.pyldavis_html = html_string
                else:
                    st.error("ç”ŸæˆPyLDAviså¯è§†åŒ–å¤±è´¥")
        
        # æ˜¾ç¤ºPyLDAvis
        if st.session_state.pyldavis_html:
            st.components.v1.html(st.session_state.pyldavis_html, width=1000, height=800)
            
            # ä¿å­˜PyLDAvisæŒ‰é’®
            if st.button("ä¿å­˜PyLDAvis", key="save_pyldavis"):
                # ä¿å­˜HTML
                save_path = os.path.join("results", f"pyldavis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                
                with open(save_path, "w", encoding="utf-8") as f:
                    f.write(st.session_state.pyldavis_html)
                
                st.success(f"å·²ä¿å­˜PyLDAviså¯è§†åŒ–è‡³: {save_path}")
    
    # æ–‡æ¡£èšç±»é€‰é¡¹å¡
    with viz_tabs[3]:
        # ç§»é™¤æ¡ä»¶åˆ¤æ–­ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
        st.subheader("æ–‡æ¡£èšç±»å¯è§†åŒ–")
        
        # è·å–æ¨¡å‹å®é™…çš„ä¸»é¢˜æ•°é‡
        actual_num_topics_for_cluster = st.session_state.lda_model.num_topics if st.session_state.lda_model else st.session_state.num_topics
        
        col1, col2 = st.columns(2)
        with col1:
            method = st.radio("é™ç»´æ–¹æ³•", ["t-SNE", "UMAP"], horizontal=True, key="clustering_method_radio")
        with col2:
            n_clusters = st.slider(
                "èšç±»æ•°é‡", 
                min_value=2, 
                max_value=min(10, len(st.session_state.corpus)),
                value=min(actual_num_topics_for_cluster, len(st.session_state.corpus)),
                key="clustering_n_clusters"
            )
        
        with st.spinner(f"æ­£åœ¨ä½¿ç”¨{method}è¿›è¡Œæ–‡æ¡£èšç±»..."):
            # ç”Ÿæˆèšç±»æ•°æ®
            df = visualizer.generate_doc_clusters(
                method=method.lower().replace('-', ''), 
                n_clusters=n_clusters
            )
            
            # ç¼“å­˜é”®
            cache_key = f"{method.lower()}_{n_clusters}"
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key not in st.session_state:
                st.session_state[cache_key] = df
            
            # ä½¿ç”¨ç¼“å­˜çš„æ•°æ®
            df = st.session_state[cache_key]
            
            # ç»˜åˆ¶æ•£ç‚¹å›¾
            fig = px.scatter(
                df, 
                x='x', 
                y='y',
                color='èšç±»',
                symbol='ä¸»å¯¼ä¸»é¢˜',
                hover_data=['æ–‡æ¡£'],
                title=f'æ–‡æ¡£èšç±»å¯è§†åŒ– ({method})',
                labels={'x': '', 'y': ''},
                color_discrete_sequence=px.colors.qualitative.Plotly
            )
            
            # è°ƒæ•´å›¾è¡¨å¸ƒå±€
            fig.update_layout(
                width=800,
                height=600,
                legend_title_text='èšç±»å’Œä¸»é¢˜'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ä¿å­˜å›¾è¡¨æŒ‰é’®
            if st.button("ä¿å­˜èšç±»å›¾", key="save_clusters"):
                # ä¿å­˜å›¾åƒ
                save_path = os.path.join("results", f"doc_clusters_{method.lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                fig.write_html(save_path)
                st.success(f"å·²ä¿å­˜èšç±»å›¾è‡³: {save_path}")
            
            # æ˜¾ç¤ºèšç±»è¯¦æƒ…
            with st.expander("æŸ¥çœ‹èšç±»è¯¦æƒ…"):
                st.dataframe(df, use_container_width=True)
    
    # ä¸»é¢˜è¯åˆ†å¸ƒé€‰é¡¹å¡
    with viz_tabs[4]:
        # ç§»é™¤æ¡ä»¶åˆ¤æ–­ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
        st.subheader("ä¸»é¢˜è¯åˆ†å¸ƒ")
        
        # è·å–æ¨¡å‹å®é™…çš„ä¸»é¢˜æ•°é‡
        actual_num_topics_for_dist = st.session_state.lda_model.num_topics if st.session_state.lda_model else st.session_state.num_topics
        
        # å‚æ•°è®¾ç½®
        num_words = st.slider("æ¯ä¸ªä¸»é¢˜æ˜¾ç¤ºè¯æ•°", 5, 30, 15, key="topic_word_num_words")
        
        with st.spinner("æ­£åœ¨ç”Ÿæˆä¸»é¢˜è¯åˆ†å¸ƒ..."):
            # ç”Ÿæˆä¸»é¢˜è¯åˆ†å¸ƒæ•°æ®
            df = visualizer.generate_topic_word_dist(num_words=num_words)
            
            # ç»˜åˆ¶æ¡å½¢å›¾
            fig = px.bar(
                df, 
                x='æ¦‚ç‡', 
                y='è¯è¯­',
                color='ä¸»é¢˜',
                facet_col='ä¸»é¢˜',
                facet_col_wrap=2,  # æ¯è¡Œæ˜¾ç¤º2ä¸ªä¸»é¢˜
                orientation='h',
                title='ä¸»é¢˜è¯åˆ†å¸ƒ',
                labels={'æ¦‚ç‡': 'è¯è¯­æ¦‚ç‡', 'è¯è¯­': 'è¯è¯­'},
                height=max(600, num_words * 30 * (actual_num_topics_for_dist + 1) // 2)  # æ ¹æ®è¯æ•°å’Œä¸»é¢˜æ•°è°ƒæ•´é«˜åº¦
            )
            
            # è°ƒæ•´å›¾è¡¨å¸ƒå±€
            fig.update_layout(
                showlegend=False,
                yaxis={'categoryorder': 'total ascending'}
            )
            
            # å¯¹æ¯ä¸ªå­å›¾è¿›è¡Œè°ƒæ•´
            for i in range(actual_num_topics_for_dist):
                fig.update_yaxes(showticklabels=True, col=i+1)
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ä¿å­˜å›¾è¡¨æŒ‰é’®
            if st.button("ä¿å­˜ä¸»é¢˜è¯åˆ†å¸ƒå›¾", key="save_topic_word_dist"):
                # ä¿å­˜å›¾åƒ
                save_path = os.path.join("results", f"topic_word_dist_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                fig.write_html(save_path)
                st.success(f"å·²ä¿å­˜ä¸»é¢˜è¯åˆ†å¸ƒå›¾è‡³: {save_path}")
    
    # ä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œé€‰é¡¹å¡
    with viz_tabs[5]:
        # ç§»é™¤æ¡ä»¶åˆ¤æ–­ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
        st.subheader("ä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ")
        
        # å‚æ•°è®¾ç½®
        threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.1, 0.9, 0.3, 0.05, key="similarity_threshold")
        
        with st.spinner("æ­£åœ¨ç”Ÿæˆä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ..."):
            # ç”Ÿæˆä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ
            G, similarity_matrix = visualizer.generate_topic_similarity_network(threshold=threshold)
            
            # æ˜¾ç¤ºç½‘ç»œå›¾
            if G.number_of_edges() > 0:
                # ä½¿ç”¨NetworkXå’ŒPlotlyç”Ÿæˆäº¤äº’å¼ç½‘ç»œå›¾
                pos = nx.spring_layout(G, seed=42)
                
                # å‡†å¤‡è¾¹å’ŒèŠ‚ç‚¹æ•°æ®
                edge_x = []
                edge_y = []
                edge_weights = []
                
                for edge in G.edges(data=True):
                    x0, y0 = pos[edge[0]]
                    x1, y1 = pos[edge[1]]
                    edge_x.extend([x0, x1, None])
                    edge_y.extend([y0, y1, None])
                    edge_weights.append(edge[2]['weight'])
                
                # åˆ›å»ºè¾¹è¿¹
                edge_trace = go.Scatter(
                    x=edge_x, y=edge_y,
                    line=dict(width=1, color='rgba(150,150,150,0.7)'),
                    hoverinfo='none',
                    mode='lines'
                )
                
                # èŠ‚ç‚¹æ•°æ®
                node_x = []
                node_y = []
                node_text = []
                node_adjacencies = []
                
                for node in G.nodes():
                    x, y = pos[node]
                    node_x.append(x)
                    node_y.append(y)
                    node_text.append(f"ä¸»é¢˜{node+1}")
                    node_adjacencies.append(len(list(G.neighbors(node))))
                
                # åˆ›å»ºèŠ‚ç‚¹è¿¹
                node_trace = go.Scatter(
                    x=node_x, y=node_y,
                    mode='markers+text',
                    text=node_text,
                    textposition="top center",
                    marker=dict(
                        showscale=True,
                        colorscale='YlGnBu',
                        reversescale=True,
                        color=node_adjacencies,
                        size=15,
                        colorbar=dict(
                            thickness=15,
                            title=dict(
                                text='è¿æ¥æ•°',
                                side='right'
                            ),
                            xanchor='left'
                        ),
                        line_width=2
                    )
                )
                
                # åˆ›å»ºç½‘ç»œå›¾
                fig = go.Figure(data=[edge_trace, node_trace],
                                 layout=go.Layout(
                                     title=dict(
                                         text='ä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ',
                                         font=dict(size=16)
                                     ),
                                     showlegend=False,
                                     hovermode='closest',
                                     margin=dict(b=20,l=5,r=5,t=40),
                                     xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                     yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
                                 ))
                
                st.plotly_chart(fig, use_container_width=True)
                
                # ä¿å­˜ç½‘ç»œå›¾æŒ‰é’®
                if st.button("ä¿å­˜ä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œ", key="save_topic_network"):
                    # ä¿å­˜å›¾åƒ
                    save_path = os.path.join("results", f"topic_network_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
                    os.makedirs(os.path.dirname(save_path), exist_ok=True)
                    fig.write_html(save_path)
                    st.success(f"å·²ä¿å­˜ä¸»é¢˜ç›¸ä¼¼æ€§ç½‘ç»œå›¾è‡³: {save_path}")
                
                # æ˜¾ç¤ºç›¸ä¼¼åº¦çŸ©é˜µ
                with st.expander("æŸ¥çœ‹ä¸»é¢˜ç›¸ä¼¼åº¦çŸ©é˜µ"):
                    # åˆ›å»ºç›¸ä¼¼åº¦çŸ©é˜µæ•°æ®æ¡†
                    topics = [f"ä¸»é¢˜{i+1}" for i in range(len(similarity_matrix))]
                    sim_df = pd.DataFrame(similarity_matrix, index=topics, columns=topics)
                    
                    # æ˜¾ç¤ºçƒ­å›¾
                    fig = px.imshow(
                        sim_df,
                        text_auto='.2f',
                        color_continuous_scale='Viridis',
                        title='ä¸»é¢˜ç›¸ä¼¼åº¦çŸ©é˜µ'
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning(f"åœ¨é˜ˆå€¼ {threshold} ä¸‹æ²¡æœ‰ä¸»é¢˜ä¹‹é—´çš„è¿æ¥ã€‚è¯·å°è¯•é™ä½é˜ˆå€¼ã€‚") 