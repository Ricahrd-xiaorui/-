import streamlit as st
import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from gensim.models import LdaModel, CoherenceModel
from datetime import datetime
import pickle
from pathlib import Path
from utils.session_state import get_session_state, log_message, update_progress

class LDAAnalyzer:
    """LDAä¸»é¢˜æ¨¡å‹åˆ†æç±»"""
    
    def __init__(self, texts, dictionary, corpus):
        self.texts = texts
        self.dictionary = dictionary
        self.corpus = corpus
        self.model = None
        self.coherence_score = None
        self.perplexity = None
        self.topic_keywords = {}
        self.doc_topic_dist = None
    
    def train_model(self, num_topics=5, iterations=50, passes=10, chunksize=None, 
                    alpha='auto', eta='auto', eval_every=10, callbacks=None):
        """è®­ç»ƒLDAæ¨¡å‹"""
        # ç¡®å®šåˆé€‚çš„chunksize
        if chunksize is None:
            chunksize = max(len(self.corpus) // 10, 100)
        
        # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°
        np.random.seed(42)
        
        # è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
        progress_bar = None
        status_text = None
        if callbacks:
            progress_bar = callbacks.get('progress_bar')
            status_text = callbacks.get('status_text')
        
        # è®­ç»ƒLDAæ¨¡å‹
        self.model = LdaModel(
            corpus=self.corpus,
            id2word=self.dictionary,
            num_topics=num_topics,
            iterations=iterations,
            passes=passes,
            chunksize=chunksize,
            alpha=alpha,
            eta=eta,
            eval_every=eval_every,
            callbacks=None  # ä¸ä½¿ç”¨Gensimå†…éƒ¨å›è°ƒ
        )
        
        # è®¡ç®—å›°æƒ‘åº¦
        self.perplexity = self.model.log_perplexity(self.corpus)
        
        # è®¡ç®—è¿è´¯æ€§åˆ†æ•°
        self.coherence_score = self._calculate_coherence()
        
        # æå–ä¸»é¢˜å…³é”®è¯
        self.topic_keywords = {i: [word for word, prob in self.model.show_topic(i, topn=20)]
                             for i in range(num_topics)}
        
        # è®¡ç®—æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒ
        self.doc_topic_dist = self._get_document_topics()
        
        return self.model
    
    def _calculate_coherence(self):
        """
        è®¡ç®—è¿è´¯æ€§åˆ†æ•°
        æ³¨æ„ï¼šä½¿ç”¨u_massæ–¹æ³•è®¡ç®—çš„è¿è´¯æ€§åˆ†æ•°é€šå¸¸ä¸ºè´Ÿå€¼ï¼Œè¶Šæ¥è¿‘0è¡¨ç¤ºä¸»é¢˜ä¸€è‡´æ€§è¶Šå¥½
        """
        try:
            # æå–ä¸»é¢˜å…³é”®è¯
            topics = []
            for i in range(self.model.num_topics):
                top_words = [word for word, _ in self.model.show_topic(i, topn=10)]
                topics.append(top_words)
            
            # ä½¿ç”¨u_massè¿è´¯æ€§æµ‹é‡ï¼ˆæ¯”c_væ›´ç¨³å®šï¼Œä¸éœ€è¦åŸå§‹æ–‡æœ¬ï¼‰
            coherence_model = CoherenceModel(
                topics=topics,
                corpus=self.corpus,
                dictionary=self.dictionary,
                coherence='u_mass'  # ä½¿ç”¨æ›´ç¨³å®šçš„u_massæ–¹æ³•
            )
            return coherence_model.get_coherence()
        except Exception as e:
            log_message(f"è®¡ç®—è¿è´¯æ€§åˆ†æ•°å¤±è´¥: {str(e)}", level="error")
            return None
    
    def _get_document_topics(self):
        """è·å–æ‰€æœ‰æ–‡æ¡£çš„ä¸»é¢˜åˆ†å¸ƒ"""
        doc_topics = []
        for i, doc in enumerate(self.corpus):
            # è·å–æ–‡æ¡£çš„ä¸»é¢˜åˆ†å¸ƒ
            topics = self.model.get_document_topics(doc, minimum_probability=0.0)
            doc_topics.append([prob for _, prob in sorted(topics)])
        
        return np.array(doc_topics)
    
    def find_optimal_topics(self, start=2, end=15, step=1, callbacks=None):
        """
        å¯»æ‰¾æœ€ä¼˜ä¸»é¢˜æ•°é‡
        æ³¨æ„ï¼šå¯¹äºu_massä¸€è‡´æ€§æµ‹é‡ï¼Œå€¼é€šå¸¸ä¸ºè´Ÿï¼Œè¶Šæ¥è¿‘0è¶Šå¥½
        """
        coherence_values = []
        perplexity_values = []
        model_list = []
        topics_range = range(start, end+1, step)
        
        total_iterations = len(topics_range)
        
        # è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
        progress_bar = None
        status_text = None
        if callbacks:
            progress_bar = callbacks.get('progress_bar')
            status_text = callbacks.get('status_text')
        
        for idx, num_topics in enumerate(topics_range):
            # æ›´æ–°è¿›åº¦
            if progress_bar:
                progress = (idx + 1) / total_iterations
                progress_bar.progress(progress)
            
            # æ›´æ–°çŠ¶æ€
            if status_text:
                status_text.text(f"è®­ç»ƒæ¨¡å‹ {num_topics} ä¸»é¢˜ ({idx+1}/{total_iterations})")
            
            # è®­ç»ƒæ¨¡å‹
            model = LdaModel(
                corpus=self.corpus,
                id2word=self.dictionary,
                num_topics=num_topics,
                iterations=50,  # ä½¿ç”¨è¾ƒå°‘çš„è¿­ä»£æ¬¡æ•°åŠ å¿«æœç´¢
                passes=5,      # ä½¿ç”¨è¾ƒå°‘çš„passesåŠ å¿«æœç´¢
                alpha='auto',
                eta='auto',
                callbacks=None  # ä¸ä½¿ç”¨å›è°ƒå‡½æ•°
            )
            
            # æ·»åŠ åˆ°æ¨¡å‹åˆ—è¡¨
            model_list.append(model)
            
            # è®¡ç®—å›°æƒ‘åº¦
            perplexity = model.log_perplexity(self.corpus)
            perplexity_values.append(perplexity)
            
            # è®¡ç®—è¿è´¯æ€§
            try:
                # æå–ä¸»é¢˜å…³é”®è¯
                topics = []
                for topic_idx in range(num_topics):
                    top_words = [word for word, _ in model.show_topic(topic_idx, topn=10)]
                    topics.append(top_words)
                
                # ä½¿ç”¨u_massè¿è´¯æ€§æµ‹é‡
                coherence_model = CoherenceModel(
                    topics=topics,
                    corpus=self.corpus,
                    dictionary=self.dictionary, 
                    coherence='u_mass'  # ä½¿ç”¨ä¸_calculate_coherenceç›¸åŒçš„æ–¹æ³•
                )
                coherence = coherence_model.get_coherence()
                coherence_values.append(coherence)
            except Exception as e:
                log_message(f"è®¡ç®—ä¸»é¢˜æ•°é‡={num_topics}çš„è¿è´¯æ€§å¤±è´¥: {str(e)}", level="error")
                coherence_values.append(0)
            
            # è®°å½•æ—¥å¿—
            log_message(f"ä¸»é¢˜æ•°é‡={num_topics}, è¿è´¯æ€§={coherence_values[-1]:.4f}, å›°æƒ‘åº¦={perplexity_values[-1]:.4f}")
        
        # æ‰¾åˆ°æœ€ä¼˜ä¸»é¢˜æ•°é‡ (å¯¹äºu_massï¼Œå¯»æ‰¾æœ€å¤§å€¼è€Œéæœ€å°å€¼ï¼Œå› ä¸ºè¶Šæ¥è¿‘0è¶Šå¥½)
        # æ³¨æ„ï¼šå¦‚æœcoherence_valueså…¨ä¸ºè´Ÿå€¼ï¼Œåˆ™é€‰æ‹©ç»å¯¹å€¼æœ€å°çš„ä½œä¸ºæœ€ä¼˜
        if all(cv < 0 for cv in coherence_values if cv != 0):
            # æ‰€æœ‰å€¼éƒ½æ˜¯è´Ÿå€¼ï¼Œæ‰¾ç»å¯¹å€¼æœ€å°çš„
            optimal_idx = np.argmin([abs(cv) for cv in coherence_values if cv != 0] or [0])
        else:
            # æœ‰æ­£å€¼æˆ–0ï¼Œæ‰¾æœ€å¤§å€¼
            optimal_idx = np.argmax(coherence_values)
            
        optimal_topics = topics_range[optimal_idx]
        
        return {
            'optimal_topics': optimal_topics,
            'coherence_values': coherence_values,
            'perplexity_values': perplexity_values,
            'topics_range': list(topics_range),
            'model_list': model_list
        }
    
    def save_model(self, filepath):
        """ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶"""
        if self.model:
            # ä¿å­˜LDAæ¨¡å‹
            self.model.save(filepath + ".gensim")
            
            # ä¿å­˜åˆ†æå™¨çŠ¶æ€
            analyzer_state = {
                'coherence_score': self.coherence_score,
                'perplexity': self.perplexity,
                'topic_keywords': self.topic_keywords,
                'doc_topic_dist': self.doc_topic_dist.tolist() if self.doc_topic_dist is not None else None
            }
            
            with open(filepath + ".pkl", 'wb') as f:
                pickle.dump(analyzer_state, f)
            
            return True
        return False
    
    @classmethod
    def load_model(cls, filepath, texts, dictionary, corpus):
        """ä»æ–‡ä»¶åŠ è½½æ¨¡å‹"""
        try:
            # åˆ›å»ºåˆ†æå™¨å®ä¾‹
            analyzer = cls(texts, dictionary, corpus)
            
            # åŠ è½½LDAæ¨¡å‹
            analyzer.model = LdaModel.load(filepath + ".gensim")
            
            # åŠ è½½åˆ†æå™¨çŠ¶æ€
            with open(filepath + ".pkl", 'rb') as f:
                analyzer_state = pickle.load(f)
            
            analyzer.coherence_score = analyzer_state.get('coherence_score')
            analyzer.perplexity = analyzer_state.get('perplexity')
            analyzer.topic_keywords = analyzer_state.get('topic_keywords', {})
            
            doc_topic_dist = analyzer_state.get('doc_topic_dist')
            if doc_topic_dist:
                analyzer.doc_topic_dist = np.array(doc_topic_dist)
            
            return analyzer
        except Exception as e:
            log_message(f"åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}", level="error")
            return None

def plot_coherence_perplexity(results):
    """
    ç»˜åˆ¶è¿è´¯æ€§å’Œå›°æƒ‘åº¦å›¾è¡¨
    æ³¨æ„ï¼š
    - å¯¹äºu_massè¿è´¯æ€§æµ‹é‡ï¼Œå€¼é€šå¸¸ä¸ºè´Ÿï¼Œè¶Šæ¥è¿‘0è¶Šå¥½
    - å›°æƒ‘åº¦(logå€¼)é€šå¸¸ä¸ºè´Ÿï¼Œå€¼è¶Šå¤§(è¶Šæ¥è¿‘0)è¡¨ç¤ºæ¨¡å‹è¶Šå¥½
    """
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']  # ä¼˜å…ˆä½¿ç”¨çš„ä¸­æ–‡å­—ä½“
    plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·
    
    fig = plt.figure(figsize=(12, 5))
    
    # åˆ›å»ºä¸¤ä¸ªå­å›¾
    ax1 = fig.add_subplot(121)
    ax2 = fig.add_subplot(122)
    
    # ç»˜åˆ¶è¿è´¯æ€§å¾—åˆ†
    ax1.plot(results['topics_range'], results['coherence_values'], marker='o')
    ax1.set_title('ä¸»é¢˜è¿è´¯æ€§è¯„åˆ† (u_mass)')
    ax1.set_xlabel('ä¸»é¢˜æ•°é‡')
    ax1.set_ylabel('è¿è´¯æ€§åˆ†æ•° (è¶Šæ¥è¿‘0è¶Šå¥½)')
    ax1.grid(True, alpha=0.3)
    
    # åœ¨æœ€ä¼˜ç‚¹æ·»åŠ æ ‡è®°
    if all(cv < 0 for cv in results['coherence_values'] if cv != 0):
        # æ‰€æœ‰å€¼éƒ½æ˜¯è´Ÿå€¼ï¼Œæ‰¾ç»å¯¹å€¼æœ€å°çš„
        abs_values = [abs(cv) for cv in results['coherence_values']]
        optimal_idx = np.argmin(abs_values)
    else:
        optimal_idx = np.argmax(results['coherence_values'])
        
    optimal_topics = results['topics_range'][optimal_idx]
    optimal_coherence = results['coherence_values'][optimal_idx]
    ax1.scatter(optimal_topics, optimal_coherence, color='red', s=100, zorder=5)
    ax1.annotate(f'æœ€ä¼˜: {optimal_topics}',
                xy=(optimal_topics, optimal_coherence),
                xytext=(optimal_topics+1, optimal_coherence),
                arrowprops=dict(arrowstyle='->'))
    
    # ç»˜åˆ¶å›°æƒ‘åº¦
    ax2.plot(results['topics_range'], results['perplexity_values'], marker='o', color='orange')
    ax2.set_title('æ¨¡å‹å›°æƒ‘åº¦ (logå€¼)')
    ax2.set_xlabel('ä¸»é¢˜æ•°é‡')
    ax2.set_ylabel('å›°æƒ‘åº¦ (logå€¼ï¼Œè¶Šæ¥è¿‘0è¶Šå¥½)')
    ax2.grid(True, alpha=0.3)
    
    # åœ¨å›°æƒ‘åº¦æœ€ä¼˜ç‚¹æ·»åŠ æ ‡è®° (å¯¹äºlogå›°æƒ‘åº¦ï¼Œå€¼è¶Šå¤§è¶Šå¥½ï¼Œå› ä¸ºé€šå¸¸ä¸ºè´Ÿå€¼)
    perp_idx = np.argmax(results['perplexity_values'])
    perp_topics = results['topics_range'][perp_idx]
    perp_value = results['perplexity_values'][perp_idx]
    ax2.scatter(perp_topics, perp_value, color='red', s=100, zorder=5)
    ax2.annotate(f'æœ€ä¼˜: {perp_topics}',
                xy=(perp_topics, perp_value),
                xytext=(perp_topics+1, perp_value),
                arrowprops=dict(arrowstyle='->'))
    
    plt.tight_layout()
    
    return fig

def render_model_trainer():
    """æ¸²æŸ“æ¨¡å‹è®­ç»ƒæ¨¡å—"""
    st.header("LDAä¸»é¢˜æ¨¡å‹è®­ç»ƒ")
    
    # åŠŸèƒ½ä»‹ç»
    with st.expander("ğŸ“– åŠŸèƒ½ä»‹ç»", expanded=False):
        st.markdown("""
        **æ¨¡å‹è®­ç»ƒæ¨¡å—** ä½¿ç”¨LDAï¼ˆæ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…ï¼‰ç®—æ³•å¯¹æ–‡æœ¬è¿›è¡Œä¸»é¢˜å»ºæ¨¡ã€‚
        
        **ä¸»è¦åŠŸèƒ½ï¼š**
        - ğŸ¯ **æ¨¡å‹è®­ç»ƒ**ï¼šæ ¹æ®è®¾å®šå‚æ•°è®­ç»ƒLDAä¸»é¢˜æ¨¡å‹
        - ğŸ” **æœ€ä¼˜ä¸»é¢˜æ•°æœç´¢**ï¼šè‡ªåŠ¨å¯»æ‰¾æœ€ä½³ä¸»é¢˜æ•°é‡
        - ğŸ’¾ **æ¨¡å‹ä¿å­˜/åŠ è½½**ï¼šä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ”¯æŒåç»­åŠ è½½ä½¿ç”¨
        
        **æ ¸å¿ƒå‚æ•°è¯´æ˜ï¼š**
        - **ä¸»é¢˜æ•°é‡**ï¼šæ¨¡å‹è¦è¯†åˆ«çš„ä¸»é¢˜ä¸ªæ•°ï¼ˆå»ºè®®3-15ä¸ªï¼‰
        - **è¿­ä»£æ¬¡æ•°**ï¼šæ¨¡å‹è®­ç»ƒçš„è¿­ä»£è½®æ•°ï¼ˆè¶Šå¤šè¶Šç²¾ç¡®ï¼Œä½†è€—æ—¶æ›´é•¿ï¼‰
        - **passes**ï¼šæ•´ä¸ªè¯­æ–™åº“çš„éå†æ¬¡æ•°
        
        **é«˜çº§å‚æ•°ï¼š**
        - **Alpha**ï¼šæ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒçš„å…ˆéªŒå‚æ•°ï¼ˆautoè‡ªåŠ¨ä¼˜åŒ–ï¼‰
        - **Eta**ï¼šä¸»é¢˜-è¯è¯­åˆ†å¸ƒçš„å…ˆéªŒå‚æ•°ï¼ˆautoè‡ªåŠ¨ä¼˜åŒ–ï¼‰
        - **Chunksize**ï¼šæ¯æ¬¡è®­ç»ƒçš„æ–‡æ¡£æ‰¹é‡å¤§å°
        
        **è¯„ä¼°æŒ‡æ ‡ï¼š**
        - **è¿è´¯æ€§åˆ†æ•°(Coherence)**ï¼šè¡¡é‡ä¸»é¢˜å†…è¯è¯­çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œä½¿ç”¨u_massæ–¹æ³•ï¼Œå€¼è¶Šæ¥è¿‘0è¶Šå¥½
        - **å›°æƒ‘åº¦(Perplexity)**ï¼šè¡¡é‡æ¨¡å‹å¯¹æ–°æ–‡æ¡£çš„é¢„æµ‹èƒ½åŠ›ï¼Œlogå€¼è¶Šæ¥è¿‘0è¶Šå¥½
        
        **ä½¿ç”¨å»ºè®®ï¼š**
        1. é¦–æ¬¡ä½¿ç”¨å»ºè®®å…ˆç”¨"å¯»æ‰¾æœ€ä¼˜ä¸»é¢˜æ•°é‡"åŠŸèƒ½
        2. æ‰¾åˆ°æœ€ä¼˜ä¸»é¢˜æ•°åï¼Œå¯ç›´æ¥ä½¿ç”¨æœ€ä¼˜æ¨¡å‹æˆ–æ‰‹åŠ¨è°ƒæ•´å‚æ•°é‡æ–°è®­ç»ƒ
        """)
    
    # æ£€æŸ¥æ˜¯å¦å®Œæˆäº†é¢„å¤„ç†
    if not st.session_state.texts or not st.session_state.dictionary or not st.session_state.corpus:
        st.warning('è¯·å…ˆåœ¨"æ–‡æœ¬é¢„å¤„ç†"é€‰é¡¹å¡ä¸­å®Œæˆæ–‡æœ¬é¢„å¤„ç†')
        return
    
    # åˆå¹¶"æ¨¡å‹å‚æ•°é…ç½®"å’Œ"é«˜çº§æ¨¡å‹å‚æ•°"ä¸ºä¸€ä¸ªé…ç½®åŒºåŸŸ
    with st.expander("æ¨¡å‹å‚æ•°é…ç½®", expanded=True):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.session_state.num_topics = st.slider(
                "ä¸»é¢˜æ•°é‡", 
                min_value=2, 
                max_value=20, 
                value=st.session_state.num_topics,
                help="LDAæ¨¡å‹çš„ä¸»é¢˜æ•°é‡",
                key="main_num_topics_slider"
            )
        
        with col2:
            st.session_state.iterations = st.number_input(
                "è¿­ä»£æ¬¡æ•°", 
                min_value=10, 
                max_value=200, 
                value=st.session_state.iterations,
                step=10,
                help="LDAæ¨¡å‹è®­ç»ƒçš„è¿­ä»£æ¬¡æ•°",
                key="main_iterations_input"
            )
        
        with col3:
            st.session_state.passes = st.number_input(
                "passes", 
                min_value=1, 
                max_value=20, 
                value=st.session_state.passes,
                step=1,
                help="LDAè®­ç»ƒä¸­çš„passesæ•°é‡",
                key="main_passes_input"
            )
        
        # é«˜çº§é€‰é¡¹åˆ‡æ¢
        show_advanced = st.checkbox("æ˜¾ç¤ºé«˜çº§é€‰é¡¹", value=False, key="show_advanced_options_checkbox")
        
        if show_advanced:
            st.markdown("---")
            st.subheader("é«˜çº§å‚æ•°")
            advanced_col1, advanced_col2, advanced_col3 = st.columns(3)
            
            with advanced_col1:
                alpha = st.radio(
                    "Alphaå‚æ•°", 
                    ["auto", "symmetric", "asymmetric"],
                    index=0,
                    help="ä¸»é¢˜-æ–‡æ¡£åˆ†å¸ƒçš„å…ˆéªŒå‚æ•°",
                    key="model_alpha_radio"
                )
            
            with advanced_col2:
                eta = st.radio(
                    "Etaå‚æ•°", 
                    ["auto", "symmetric"],
                    index=0,
                    help="è¯-ä¸»é¢˜åˆ†å¸ƒçš„å…ˆéªŒå‚æ•°",
                    key="model_eta_radio"
                )
            
            with advanced_col3:
                chunksize = st.number_input(
                    "Chunksize", 
                    min_value=100, 
                    max_value=5000, 
                    value=2000, 
                    step=100,
                    help="æ¯æ¬¡è®­ç»ƒçš„æ–‡æ¡£æ‰¹é‡å¤§å°",
                    key="model_chunksize_input"
                )
        else:
            alpha = "auto"
            eta = "auto"
            chunksize = None
    
    # è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜ä¸»é¢˜æ•°é‡
    with st.expander("å¯»æ‰¾æœ€ä¼˜ä¸»é¢˜æ•°é‡", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            start_topics = st.number_input("èµ·å§‹ä¸»é¢˜æ•°", min_value=2, max_value=15, value=2, key="start_topics_input")
        
        with col2:
            end_topics = st.number_input("ç»“æŸä¸»é¢˜æ•°", min_value=3, max_value=20, value=15, key="end_topics_input")
        
        with col3:
            step = st.number_input("æ­¥é•¿", min_value=1, max_value=5, value=1, key="topics_step_input")
        
        if st.button("å¯»æ‰¾æœ€ä¼˜ä¸»é¢˜æ•°é‡", key="find_optimal_topics"):
            # æ£€æŸ¥å‚æ•°æœ‰æ•ˆæ€§
            if start_topics >= end_topics:
                st.error("èµ·å§‹ä¸»é¢˜æ•°å¿…é¡»å°äºç»“æŸä¸»é¢˜æ•°")
            else:
                with st.spinner("æ­£åœ¨å¯»æ‰¾æœ€ä¼˜ä¸»é¢˜æ•°é‡..."):
                    start_time = time.time()
                    
                    # åˆ›å»ºLDAåˆ†æå™¨
                    analyzer = LDAAnalyzer(
                        st.session_state.texts,
                        st.session_state.dictionary,
                        st.session_state.corpus
                    )
                    
                    # è¿›åº¦æ¡
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # å‡†å¤‡å›è°ƒå‚æ•°
                    callbacks = {
                        'progress_bar': progress_bar,
                        'status_text': status_text
                    }
                    
                    # å¯»æ‰¾æœ€ä¼˜ä¸»é¢˜æ•°é‡
                    results = analyzer.find_optimal_topics(
                        start=start_topics,
                        end=end_topics,
                        step=step,
                        callbacks=callbacks  # ä¼ é€’å›è°ƒå‚æ•°
                    )
                    
                    # ç¡®ä¿è¿›åº¦è¾¾åˆ°100%
                    progress_bar.progress(1.0)
                    status_text.text("æœ€ä¼˜ä¸»é¢˜æ•°é‡æœç´¢å®Œæˆ")
                    
                    # ä¿å­˜æœç´¢ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.optimal_search_results = results
                    
                    # ç»˜åˆ¶ç»“æœå›¾è¡¨
                    fig = plot_coherence_perplexity(results)
                    st.pyplot(fig)
                    
                    # æ˜¾ç¤ºæœ€ä¼˜ä¸»é¢˜æ•°é‡
                    optimal_topics = results['optimal_topics']
                    st.success(f"å·²æ‰¾åˆ°æœ€ä¼˜ä¸»é¢˜æ•°é‡: {optimal_topics}")
                    
                    # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„ä¸»é¢˜æ•°é‡
                    st.session_state.num_topics = optimal_topics
                    
                    # è®°å½•æ—¥å¿—
                    elapsed_time = time.time() - start_time
                    log_message(f"æœ€ä¼˜ä¸»é¢˜æ•°é‡æœç´¢å®Œæˆï¼Œæœ€ä¼˜å€¼: {optimal_topics}ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’", level="success")
        
        # å¦‚æœæœ‰æœç´¢ç»“æœï¼Œæ˜¾ç¤º"ä½¿ç”¨æœ€ä¼˜æ¨¡å‹"æŒ‰é’®
        if st.session_state.get("optimal_search_results"):
            results = st.session_state.optimal_search_results
            optimal_idx = results['topics_range'].index(results['optimal_topics'])
            
            st.info(f"ğŸ’¡ å·²æ‰¾åˆ°æœ€ä¼˜ä¸»é¢˜æ•°: {results['optimal_topics']}ï¼Œè¿è´¯æ€§: {results['coherence_values'][optimal_idx]:.4f}")
            
            if st.button("ğŸš€ ç›´æ¥ä½¿ç”¨æœ€ä¼˜æ¨¡å‹", key="use_optimal_model", type="primary"):
                with st.spinner("æ­£åœ¨åº”ç”¨æœ€ä¼˜æ¨¡å‹..."):
                    # è·å–æœ€ä¼˜æ¨¡å‹
                    optimal_model = results['model_list'][optimal_idx]
                    
                    # åˆ›å»ºåˆ†æå™¨å¹¶è®¾ç½®æ¨¡å‹
                    analyzer = LDAAnalyzer(
                        st.session_state.texts,
                        st.session_state.dictionary,
                        st.session_state.corpus
                    )
                    analyzer.model = optimal_model
                    analyzer.coherence_score = results['coherence_values'][optimal_idx]
                    analyzer.perplexity = results['perplexity_values'][optimal_idx]
                    
                    # æå–ä¸»é¢˜å…³é”®è¯
                    analyzer.topic_keywords = {i: [word for word, prob in optimal_model.show_topic(i, topn=20)]
                                             for i in range(optimal_model.num_topics)}
                    
                    # è®¡ç®—æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒ
                    analyzer.doc_topic_dist = analyzer._get_document_topics()
                    
                    # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.lda_model = optimal_model
                    st.session_state.num_topics = results['optimal_topics']
                    st.session_state.coherence_score = analyzer.coherence_score
                    st.session_state.perplexity = analyzer.perplexity
                    st.session_state.topic_keywords = analyzer.topic_keywords
                    st.session_state.doc_topic_dist = analyzer.doc_topic_dist
                    st.session_state.training_complete = True
                    
                    # ä¿å­˜æ¨¡å‹
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    model_path = os.path.join("models", f"lda_model_{results['optimal_topics']}topics_{timestamp}")
                    os.makedirs(os.path.dirname(model_path), exist_ok=True)
                    
                    if analyzer.save_model(model_path):
                        st.session_state.model_path = model_path
                        log_message(f"æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}", level="success")
                    
                    st.success(f"å·²åº”ç”¨æœ€ä¼˜æ¨¡å‹ï¼ˆ{results['optimal_topics']}ä¸ªä¸»é¢˜ï¼‰")
                    log_message(f"å·²åº”ç”¨æœ€ä¼˜æ¨¡å‹ï¼Œä¸»é¢˜æ•°: {results['optimal_topics']}", level="success")
                    
                    # æ¸…ç†æœç´¢ç»“æœ
                    del st.session_state.optimal_search_results
                    st.rerun()
    
    # è®­ç»ƒæ¨¡å‹æŒ‰é’®
    if st.button("å¼€å§‹è®­ç»ƒLDAæ¨¡å‹", key="train_lda_model"):
        with st.spinner("æ­£åœ¨è®­ç»ƒLDAæ¨¡å‹..."):
            start_time = time.time()
            
            # è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆ›å»ºLDAåˆ†æå™¨
            analyzer = LDAAnalyzer(
                st.session_state.texts,
                st.session_state.dictionary,
                st.session_state.corpus
            )
            
            # å‡†å¤‡å›è°ƒå‚æ•°
            callbacks = {
                'progress_bar': progress_bar,
                'status_text': status_text
            }
            
            # è®­ç»ƒæ¨¡å‹
            model = analyzer.train_model(
                num_topics=st.session_state.num_topics,
                iterations=st.session_state.iterations,
                passes=st.session_state.passes,
                chunksize=chunksize if show_advanced else None,
                alpha=alpha if show_advanced else 'auto',
                eta=eta if show_advanced else 'auto',
                callbacks=callbacks  # ä¼ é€’åŒ…å«UIå…ƒç´ çš„å­—å…¸
            )
            
            # æ‰‹åŠ¨æ›´æ–°è¿›åº¦åˆ°100%
            progress_bar.progress(1.0)
            status_text.text("æ¨¡å‹è®­ç»ƒå®Œæˆ")
            
            # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.lda_model = model
            st.session_state.coherence_score = analyzer.coherence_score
            st.session_state.perplexity = analyzer.perplexity
            st.session_state.topic_keywords = analyzer.topic_keywords
            st.session_state.doc_topic_dist = analyzer.doc_topic_dist
            st.session_state.training_complete = True
            st.session_state.training_time = time.time() - start_time
            
            # ä¿å­˜æ¨¡å‹
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_path = os.path.join("models", f"lda_model_{st.session_state.num_topics}topics_{timestamp}")
            os.makedirs(os.path.dirname(model_path), exist_ok=True)
            
            if analyzer.save_model(model_path):
                st.session_state.model_path = model_path
                log_message(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}", level="success")
            
            # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
            elapsed_time = time.time() - start_time
            st.success(f"LDAæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            log_message(f"LDAæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä¸»é¢˜æ•°: {st.session_state.num_topics}ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’", level="success")
    
    # åŠ è½½å·²æœ‰æ¨¡å‹
    with st.expander("åŠ è½½å·²æœ‰æ¨¡å‹", expanded=False):
        model_files = [f for f in os.listdir("models") if f.endswith(".gensim")]
        
        if model_files:
            selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹æ–‡ä»¶", model_files, key="model_file_select")
            
            if st.button("åŠ è½½æ¨¡å‹", key="load_model"):
                with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
                    model_path = os.path.join("models", selected_model[:-7])  # å»æ‰.gensimåç¼€
                    
                    # åŠ è½½æ¨¡å‹
                    analyzer = LDAAnalyzer.load_model(
                        model_path,
                        st.session_state.texts,
                        st.session_state.dictionary,
                        st.session_state.corpus
                    )
                    
                    if analyzer and analyzer.model:
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.lda_model = analyzer.model
                        st.session_state.coherence_score = analyzer.coherence_score
                        st.session_state.perplexity = analyzer.perplexity
                        st.session_state.topic_keywords = analyzer.topic_keywords
                        st.session_state.doc_topic_dist = analyzer.doc_topic_dist
                        st.session_state.training_complete = True
                        st.session_state.model_path = model_path
                        
                        st.success(f"æˆåŠŸåŠ è½½æ¨¡å‹: {selected_model}")
                        log_message(f"å·²åŠ è½½æ¨¡å‹: {selected_model}", level="success")
                    else:
                        st.error("æ¨¡å‹åŠ è½½å¤±è´¥")
        else:
            st.info("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
    
    # æ˜¾ç¤ºè®­ç»ƒç»“æœ
    if st.session_state.training_complete and st.session_state.lda_model:
        st.subheader("æ¨¡å‹è®­ç»ƒç»“æœ")
        
        # æ˜¾ç¤ºæ¨¡å‹åŸºæœ¬ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ä¸»é¢˜æ•°é‡", st.session_state.num_topics)
        
        with col2:
            coherence = st.session_state.coherence_score
            if coherence is not None:
                st.metric("è¿è´¯æ€§åˆ†æ•°", f"{coherence:.4f}")
            else:
                st.metric("è¿è´¯æ€§åˆ†æ•°", "N/A")
        
        with col3:
            perplexity = st.session_state.perplexity
            if perplexity is not None:
                st.metric("å›°æƒ‘åº¦", f"{perplexity:.4f}")
            else:
                st.metric("å›°æƒ‘åº¦", "N/A")
        
        # æ˜¾ç¤ºä¸»é¢˜å…³é”®è¯
        st.subheader("ä¸»é¢˜å…³é”®è¯")
        
        # åˆ›å»ºé€‰é¡¹å¡æ˜¾ç¤ºæ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯
        topic_tabs = st.tabs([f"ä¸»é¢˜ {i+1}" for i in range(st.session_state.num_topics)])
        
        for i, tab in enumerate(topic_tabs):
            with tab:
                # è·å–ä¸»é¢˜çš„å…³é”®è¯
                if i in st.session_state.topic_keywords:
                    keywords = st.session_state.topic_keywords[i]
                    
                    # æ˜¾ç¤ºå…³é”®è¯åˆ—è¡¨
                    st.write(f"**ä¸»é¢˜ {i+1} çš„å‰20ä¸ªå…³é”®è¯**")
                    
                    # åˆ›å»ºå…³é”®è¯è¡¨æ ¼
                    keywords_df = pd.DataFrame({
                        "å…³é”®è¯": keywords,
                        "ç´¢å¼•": range(1, len(keywords) + 1)
                    }).set_index("ç´¢å¼•")
                    
                    st.dataframe(keywords_df, use_container_width=True)
                else:
                    st.write("è¯¥ä¸»é¢˜æ²¡æœ‰å…³é”®è¯æ•°æ®")
        
        # ä¿å­˜ä¸»é¢˜å…³é”®è¯åˆ°CSV
        if st.button("ä¿å­˜ä¸»é¢˜å…³é”®è¯åˆ°CSV", key="save_keywords"):
            # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰ä¸»é¢˜å…³é”®è¯çš„DataFrame
            all_keywords = {}
            max_keywords = 0
            
            for topic_id, keywords in st.session_state.topic_keywords.items():
                all_keywords[f"ä¸»é¢˜{topic_id+1}"] = keywords
                max_keywords = max(max_keywords, len(keywords))
            
            # ç¡®ä¿æ‰€æœ‰åˆ—çš„é•¿åº¦ç›¸åŒ
            for topic, keywords in all_keywords.items():
                if len(keywords) < max_keywords:
                    all_keywords[topic] = keywords + [""] * (max_keywords - len(keywords))
            
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(all_keywords)
            
            # ä¿å­˜åˆ°CSV
            csv_path = os.path.join("results", f"topic_keywords_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
            os.makedirs(os.path.dirname(csv_path), exist_ok=True)
            df.to_csv(csv_path, encoding="utf-8-sig", index=False)
            
            st.success(f"ä¸»é¢˜å…³é”®è¯å·²ä¿å­˜åˆ°: {csv_path}")
            log_message(f"ä¸»é¢˜å…³é”®è¯å·²ä¿å­˜åˆ°: {csv_path}", level="success") 