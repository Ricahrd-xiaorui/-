# -*- coding: utf-8 -*-
"""
å¼•ç”¨ä¸å‚è€ƒåˆ†ææ¨¡å— (Citation Analysis Module)
=============================================

æœ¬æ¨¡å—æä¾›æ”¿ç­–æ–‡æœ¬é—´çš„å¼•ç”¨å…³ç³»åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- å¼•ç”¨æå–ï¼ˆè¯†åˆ«æ–‡æœ¬ä¸­å¯¹å…¶ä»–æ”¿ç­–æ–‡ä»¶çš„å¼•ç”¨ï¼‰
- å¼•ç”¨ç½‘ç»œæ„å»º
- æ ¸å¿ƒæ–‡æ¡£è¯†åˆ«
- å¼•ç”¨å…³ç³»å¯è§†åŒ–
- ç»“æœå¯¼å‡º

Requirements: 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7
"""

from typing import List, Dict, Tuple, Optional, Set
from collections import Counter, defaultdict
from dataclasses import dataclass, field
import pandas as pd
import numpy as np
import re


@dataclass
class Citation:
    """å¼•ç”¨æ•°æ®ç±»"""
    source_doc: str  # å¼•ç”¨æ¥æºæ–‡æ¡£
    cited_text: str  # è¢«å¼•ç”¨çš„æ–‡æœ¬/æ–‡ä»¶å
    context: str = ""  # å¼•ç”¨ä¸Šä¸‹æ–‡
    position: int = 0  # åœ¨æ–‡æ¡£ä¸­çš„ä½ç½®


@dataclass
class CitationStats:
    """å¼•ç”¨ç»Ÿè®¡æ•°æ®ç±»"""
    doc_name: str
    cited_by_count: int  # è¢«å¼•ç”¨æ¬¡æ•°
    cites_count: int  # å¼•ç”¨å…¶ä»–æ–‡æ¡£æ¬¡æ•°
    cited_by: List[str] = field(default_factory=list)  # è¢«å“ªäº›æ–‡æ¡£å¼•ç”¨
    cites: List[str] = field(default_factory=list)  # å¼•ç”¨äº†å“ªäº›æ–‡æ¡£


class CitationAnalyzer:
    """
    å¼•ç”¨åˆ†æå™¨ - åˆ†ææ”¿ç­–æ–‡æœ¬é—´çš„å¼•ç”¨å…³ç³»
    
    Attributes:
        raw_texts: åŸå§‹æ–‡æœ¬åˆ—è¡¨
        file_names: æ–‡æ¡£åç§°åˆ—è¡¨
        citations: æå–çš„å¼•ç”¨åˆ—è¡¨
    
    Requirements: 6.1, 6.2, 6.3, 6.5, 6.6
    """
    
    # ä¸­æ–‡æ”¿ç­–æ–‡ä»¶å¼•ç”¨æ¨¡å¼
    CITATION_PATTERNS = [
        # ã€Šxxxã€‹æ ¼å¼
        r'ã€Š([^ã€‹]+)ã€‹',
        # æ ¹æ®xxxè§„å®š
        r'æ ¹æ®[ã€Œã€Œ]?([^ã€ã€ï¼Œã€‚ã€\s]+)[ã€ã€]?(?:çš„)?(?:è§„å®š|è¦æ±‚|ç²¾ç¥)',
        # ä¾æ®xxx
        r'ä¾æ®[ã€Œã€Œ]?([^ã€ã€ï¼Œã€‚ã€\s]+)[ã€ã€]?',
        # æŒ‰ç…§xxx
        r'æŒ‰ç…§[ã€Œã€Œ]?([^ã€ã€ï¼Œã€‚ã€\s]+)[ã€ã€]?(?:çš„)?(?:è§„å®š|è¦æ±‚)',
        # å‚ç…§xxx
        r'å‚ç…§[ã€Œã€Œ]?([^ã€ã€ï¼Œã€‚ã€\s]+)[ã€ã€]?',
        # è´¯å½»xxx
        r'è´¯å½»[ã€Œã€Œ]?([^ã€ã€ï¼Œã€‚ã€\s]+)[ã€ã€]?',
        # è½å®xxx
        r'è½å®[ã€Œã€Œ]?([^ã€ã€ï¼Œã€‚ã€\s]+)[ã€ã€]?',
        # xxxå·æ–‡
        r'([^\sï¼Œã€‚ã€]+(?:å·|å­—)[^\sï¼Œã€‚ã€]*æ–‡)',
        # xxxé€šçŸ¥/æ„è§/åŠæ³•ç­‰
        r'[ã€Œã€Œ]([^ã€ã€]+(?:é€šçŸ¥|æ„è§|åŠæ³•|è§„å®š|æ¡ä¾‹|æ³•|å†³å®š|æ–¹æ¡ˆ|çº²è¦|è§„åˆ’))[ã€ã€]',
    ]
    
    def __init__(self, raw_texts: List[str], file_names: List[str]):
        """
        åˆå§‹åŒ–å¼•ç”¨åˆ†æå™¨
        
        Args:
            raw_texts: åŸå§‹æ–‡æœ¬åˆ—è¡¨
            file_names: æ–‡æ¡£åç§°åˆ—è¡¨
        """
        self.raw_texts = raw_texts if raw_texts else []
        self.file_names = file_names if file_names else []
        self.citations: List[Citation] = []
        self._citation_network: Optional[Dict[str, List[str]]] = None
        self._compiled_patterns = [re.compile(p) for p in self.CITATION_PATTERNS]
    
    def extract_citations(self) -> Dict[str, List[str]]:
        """
        ä»æ‰€æœ‰æ–‡æ¡£ä¸­æå–å¼•ç”¨
        
        Returns:
            Dict[str, List[str]]: æ–‡æ¡£å -> è¢«å¼•ç”¨æ–‡ä»¶ååˆ—è¡¨
        
        Requirements: 6.1, 6.2
        """
        self.citations = []
        citation_map: Dict[str, List[str]] = defaultdict(list)
        
        for doc_idx, raw_text in enumerate(self.raw_texts):
            if doc_idx >= len(self.file_names):
                continue
            
            doc_name = self.file_names[doc_idx]
            cited_texts = self._extract_citations_from_text(raw_text, doc_name)
            
            for citation in cited_texts:
                self.citations.append(citation)
                if citation.cited_text not in citation_map[doc_name]:
                    citation_map[doc_name].append(citation.cited_text)
        
        self._citation_network = dict(citation_map)
        return self._citation_network
    
    def _extract_citations_from_text(self, text: str, doc_name: str) -> List[Citation]:
        """
        ä»å•ä¸ªæ–‡æœ¬ä¸­æå–å¼•ç”¨
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            doc_name: æ–‡æ¡£åç§°
        
        Returns:
            List[Citation]: å¼•ç”¨åˆ—è¡¨
        """
        if not text:
            return []
        
        citations = []
        seen_citations: Set[str] = set()
        
        for pattern in self._compiled_patterns:
            for match in pattern.finditer(text):
                cited_text = match.group(1).strip()
                
                # æ¸…ç†å¼•ç”¨æ–‡æœ¬ï¼ˆç§»é™¤å¤šä½™çš„æ ‡ç‚¹å’Œç©ºç™½ï¼‰
                cited_text = self._clean_citation_text(cited_text)
                
                # è¿‡æ»¤æ— æ•ˆå¼•ç”¨
                if not self._is_valid_citation(cited_text):
                    continue
                
                # å»é‡ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–åçš„æ–‡æœ¬ï¼‰
                normalized = self._normalize_citation(cited_text)
                if normalized in seen_citations:
                    continue
                seen_citations.add(normalized)
                
                # æå–ä¸Šä¸‹æ–‡ï¼ˆå‰åå„50ä¸ªå­—ç¬¦ï¼‰
                start = max(0, match.start() - 50)
                end = min(len(text), match.end() + 50)
                context = text[start:end]
                
                citations.append(Citation(
                    source_doc=doc_name,
                    cited_text=cited_text,
                    context=context,
                    position=match.start()
                ))
        
        return citations
    
    def _clean_citation_text(self, text: str) -> str:
        """
        æ¸…ç†å¼•ç”¨æ–‡æœ¬
        
        Args:
            text: åŸå§‹å¼•ç”¨æ–‡æœ¬
        
        Returns:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤é¦–å°¾çš„ä¹¦åå·
        text = re.sub(r'^[ã€Šã€Œã€Œ\s]+', '', text)
        text = re.sub(r'[ã€‹ã€ã€\s]+$', '', text)
        
        # ç§»é™¤æœ«å°¾çš„"çš„"ã€"ç²¾ç¥"ç­‰åç¼€ï¼ˆä»…å½“å®ƒä»¬æ˜¯ç‹¬ç«‹çš„åç¼€æ—¶ï¼‰
        text = re.sub(r'ã€‹çš„$', '', text)
        text = re.sub(r'ã€‹ç²¾ç¥$', '', text)
        text = re.sub(r'ã€‹è¦æ±‚$', '', text)
        text = re.sub(r'ã€‹è§„å®š$', '', text)
        
        return text.strip()
    
    def _normalize_citation(self, text: str) -> str:
        """
        æ ‡å‡†åŒ–å¼•ç”¨æ–‡æœ¬ç”¨äºå»é‡
        
        Args:
            text: å¼•ç”¨æ–‡æœ¬
        
        Returns:
            str: æ ‡å‡†åŒ–åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤æ‰€æœ‰æ ‡ç‚¹å’Œç©ºç™½
        normalized = re.sub(r'[ã€Šã€‹ã€Œã€ã€Œã€\s]', '', text)
        return normalized.lower()
    
    def _is_valid_citation(self, cited_text: str) -> bool:
        """
        éªŒè¯å¼•ç”¨æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            cited_text: è¢«å¼•ç”¨çš„æ–‡æœ¬
        
        Returns:
            bool: æ˜¯å¦ä¸ºæœ‰æ•ˆå¼•ç”¨
        """
        if not cited_text:
            return False
        
        # é•¿åº¦æ£€æŸ¥
        if len(cited_text) < 2 or len(cited_text) > 100:
            return False
        
        # æ’é™¤å¸¸è§çš„éå¼•ç”¨å†…å®¹
        invalid_patterns = [
            r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[æ¡ç« èŠ‚æ¬¾é¡¹]',  # æ¡æ¬¾å¼•ç”¨
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ã€.]',  # åºå·
            r'^[\d]+$',  # çº¯æ•°å­—
            r'^[a-zA-Z\s]+$',  # çº¯è‹±æ–‡
        ]
        
        for pattern in invalid_patterns:
            if re.match(pattern, cited_text):
                return False
        
        return True
    
    def get_all_citations(self) -> List[Citation]:
        """
        è·å–æ‰€æœ‰æå–çš„å¼•ç”¨
        
        Returns:
            List[Citation]: å¼•ç”¨åˆ—è¡¨
        """
        if not self.citations:
            self.extract_citations()
        return self.citations
    
    def get_citations_by_document(self, doc_name: str) -> List[Citation]:
        """
        è·å–æŒ‡å®šæ–‡æ¡£çš„æ‰€æœ‰å¼•ç”¨
        
        Args:
            doc_name: æ–‡æ¡£åç§°
        
        Returns:
            List[Citation]: è¯¥æ–‡æ¡£çš„å¼•ç”¨åˆ—è¡¨
        """
        if not self.citations:
            self.extract_citations()
        return [c for c in self.citations if c.source_doc == doc_name]
    
    def get_cited_documents(self, doc_name: str) -> List[str]:
        """
        è·å–æŒ‡å®šæ–‡æ¡£å¼•ç”¨çš„æ‰€æœ‰æ–‡æ¡£
        
        Args:
            doc_name: æ–‡æ¡£åç§°
        
        Returns:
            List[str]: è¢«å¼•ç”¨çš„æ–‡æ¡£ååˆ—è¡¨
        """
        if self._citation_network is None:
            self.extract_citations()
        return self._citation_network.get(doc_name, [])
    
    def build_citation_network(self) -> Dict[str, Dict[str, List[str]]]:
        """
        æ„å»ºå¼•ç”¨å…³ç³»ç½‘ç»œ
        
        Returns:
            Dict: åŒ…å« 'nodes' å’Œ 'edges' çš„ç½‘ç»œæ•°æ®
        
        Requirements: 6.3
        """
        if self._citation_network is None:
            self.extract_citations()
        
        # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹ï¼ˆæ–‡æ¡£å’Œè¢«å¼•ç”¨çš„æ–‡ä»¶ï¼‰
        nodes: Set[str] = set(self.file_names)
        edges: List[Tuple[str, str]] = []
        
        for source_doc, cited_docs in self._citation_network.items():
            for cited_doc in cited_docs:
                nodes.add(cited_doc)
                edges.append((source_doc, cited_doc))
        
        return {
            'nodes': list(nodes),
            'edges': edges
        }
    
    def get_citation_count(self, doc_name: str) -> Tuple[int, int]:
        """
        è·å–æ–‡æ¡£çš„å¼•ç”¨ç»Ÿè®¡
        
        Args:
            doc_name: æ–‡æ¡£åç§°
        
        Returns:
            Tuple[int, int]: (è¢«å¼•ç”¨æ¬¡æ•°, å¼•ç”¨å…¶ä»–æ–‡æ¡£æ¬¡æ•°)
        
        Requirements: 6.5
        """
        if self._citation_network is None:
            self.extract_citations()
        
        # è®¡ç®—å¼•ç”¨å…¶ä»–æ–‡æ¡£çš„æ¬¡æ•°
        cites_count = len(self._citation_network.get(doc_name, []))
        
        # è®¡ç®—è¢«å¼•ç”¨æ¬¡æ•°
        cited_by_count = 0
        for source_doc, cited_docs in self._citation_network.items():
            if doc_name in cited_docs or any(doc_name in cd for cd in cited_docs):
                cited_by_count += 1
        
        return (cited_by_count, cites_count)
    
    def get_all_citation_stats(self) -> List[CitationStats]:
        """
        è·å–æ‰€æœ‰æ–‡æ¡£çš„å¼•ç”¨ç»Ÿè®¡
        
        Returns:
            List[CitationStats]: å¼•ç”¨ç»Ÿè®¡åˆ—è¡¨
        """
        if self._citation_network is None:
            self.extract_citations()
        
        stats = []
        
        # æ”¶é›†æ‰€æœ‰æ–‡æ¡£ï¼ˆåŒ…æ‹¬è¢«å¼•ç”¨ä½†ä¸åœ¨æ–‡ä»¶åˆ—è¡¨ä¸­çš„ï¼‰
        all_docs: Set[str] = set(self.file_names)
        for cited_docs in self._citation_network.values():
            all_docs.update(cited_docs)
        
        for doc_name in all_docs:
            # è®¡ç®—è¢«å“ªäº›æ–‡æ¡£å¼•ç”¨
            cited_by = []
            for source_doc, cited_docs in self._citation_network.items():
                if doc_name in cited_docs:
                    cited_by.append(source_doc)
            
            # è®¡ç®—å¼•ç”¨äº†å“ªäº›æ–‡æ¡£
            cites = self._citation_network.get(doc_name, [])
            
            stats.append(CitationStats(
                doc_name=doc_name,
                cited_by_count=len(cited_by),
                cites_count=len(cites),
                cited_by=cited_by,
                cites=cites
            ))
        
        return stats
    
    def find_core_documents(self, top_n: int = 5) -> List[Tuple[str, int]]:
        """
        è¯†åˆ«å¼•ç”¨ç½‘ç»œä¸­çš„æ ¸å¿ƒæ–‡æ¡£ï¼ˆé«˜è¢«å¼•æ–‡æ¡£ï¼‰
        
        Args:
            top_n: è¿”å›çš„æ ¸å¿ƒæ–‡æ¡£æ•°é‡
        
        Returns:
            List[Tuple[str, int]]: (æ–‡æ¡£å, è¢«å¼•ç”¨æ¬¡æ•°) åˆ—è¡¨ï¼ŒæŒ‰è¢«å¼•ç”¨æ¬¡æ•°é™åºæ’åˆ—
        
        Requirements: 6.6
        """
        if self._citation_network is None:
            self.extract_citations()
        
        # ç»Ÿè®¡æ¯ä¸ªæ–‡æ¡£è¢«å¼•ç”¨çš„æ¬¡æ•°
        citation_counts: Counter = Counter()
        
        for source_doc, cited_docs in self._citation_network.items():
            for cited_doc in cited_docs:
                citation_counts[cited_doc] += 1
        
        # æŒ‰è¢«å¼•ç”¨æ¬¡æ•°é™åºæ’åº
        sorted_docs = citation_counts.most_common(top_n)
        
        return sorted_docs
    
    def get_citation_matrix(self) -> Tuple[pd.DataFrame, List[str]]:
        """
        ç”Ÿæˆå¼•ç”¨çŸ©é˜µ
        
        Returns:
            Tuple[pd.DataFrame, List[str]]: (å¼•ç”¨çŸ©é˜µDataFrame, æ–‡æ¡£ååˆ—è¡¨)
        """
        if self._citation_network is None:
            self.extract_citations()
        
        # æ”¶é›†æ‰€æœ‰æ–‡æ¡£
        all_docs: Set[str] = set(self.file_names)
        for cited_docs in self._citation_network.values():
            all_docs.update(cited_docs)
        
        doc_list = sorted(list(all_docs))
        n = len(doc_list)
        
        # åˆ›å»ºçŸ©é˜µ
        matrix = np.zeros((n, n), dtype=int)
        doc_to_idx = {doc: i for i, doc in enumerate(doc_list)}
        
        for source_doc, cited_docs in self._citation_network.items():
            if source_doc in doc_to_idx:
                source_idx = doc_to_idx[source_doc]
                for cited_doc in cited_docs:
                    if cited_doc in doc_to_idx:
                        cited_idx = doc_to_idx[cited_doc]
                        matrix[source_idx][cited_idx] = 1
        
        df = pd.DataFrame(matrix, index=doc_list, columns=doc_list)
        return df, doc_list

    def export_network_data(self) -> str:
        """
        å¯¼å‡ºå¼•ç”¨ç½‘ç»œæ•°æ®ä¸ºCSVæ ¼å¼
        
        Returns:
            str: CSVæ ¼å¼å­—ç¬¦ä¸²
        
        Requirements: 6.7
        """
        if self._citation_network is None:
            self.extract_citations()
        
        # æ„å»ºè¾¹åˆ—è¡¨æ•°æ®
        data = []
        for source_doc, cited_docs in self._citation_network.items():
            for cited_doc in cited_docs:
                data.append({
                    "å¼•ç”¨æ–‡æ¡£": source_doc,
                    "è¢«å¼•ç”¨æ–‡æ¡£": cited_doc
                })
        
        if not data:
            return ""
        
        df = pd.DataFrame(data)
        return df.to_csv(index=False, encoding='utf-8-sig')
    
    def export_citation_list(self) -> str:
        """
        å¯¼å‡ºå¼•ç”¨åˆ—è¡¨ä¸ºCSVæ ¼å¼
        
        Returns:
            str: CSVæ ¼å¼å­—ç¬¦ä¸²
        """
        if not self.citations:
            self.extract_citations()
        
        data = []
        for citation in self.citations:
            data.append({
                "æ¥æºæ–‡æ¡£": citation.source_doc,
                "è¢«å¼•ç”¨å†…å®¹": citation.cited_text,
                "å¼•ç”¨ä¸Šä¸‹æ–‡": citation.context,
                "ä½ç½®": citation.position
            })
        
        if not data:
            return ""
        
        df = pd.DataFrame(data)
        return df.to_csv(index=False, encoding='utf-8-sig')
    
    def export_citation_stats(self) -> str:
        """
        å¯¼å‡ºå¼•ç”¨ç»Ÿè®¡ä¸ºCSVæ ¼å¼
        
        Returns:
            str: CSVæ ¼å¼å­—ç¬¦ä¸²
        """
        stats = self.get_all_citation_stats()
        
        data = []
        for stat in stats:
            data.append({
                "æ–‡æ¡£å": stat.doc_name,
                "è¢«å¼•ç”¨æ¬¡æ•°": stat.cited_by_count,
                "å¼•ç”¨æ¬¡æ•°": stat.cites_count,
                "è¢«å¼•ç”¨æ¥æº": ", ".join(stat.cited_by[:5]),
                "å¼•ç”¨ç›®æ ‡": ", ".join(stat.cites[:5])
            })
        
        if not data:
            return ""
        
        df = pd.DataFrame(data)
        # æŒ‰è¢«å¼•ç”¨æ¬¡æ•°é™åºæ’åº
        df = df.sort_values("è¢«å¼•ç”¨æ¬¡æ•°", ascending=False)
        return df.to_csv(index=False, encoding='utf-8-sig')
    
    def get_network_for_visualization(self) -> Tuple[List[Dict], List[Dict]]:
        """
        è·å–ç”¨äºå¯è§†åŒ–çš„ç½‘ç»œæ•°æ®
        
        Returns:
            Tuple[List[Dict], List[Dict]]: (èŠ‚ç‚¹åˆ—è¡¨, è¾¹åˆ—è¡¨)
        """
        if self._citation_network is None:
            self.extract_citations()
        
        # ç»Ÿè®¡è¢«å¼•ç”¨æ¬¡æ•°ç”¨äºèŠ‚ç‚¹å¤§å°
        citation_counts: Counter = Counter()
        for cited_docs in self._citation_network.values():
            for cited_doc in cited_docs:
                citation_counts[cited_doc] += 1
        
        # æ„å»ºèŠ‚ç‚¹åˆ—è¡¨
        all_docs: Set[str] = set(self.file_names)
        for cited_docs in self._citation_network.values():
            all_docs.update(cited_docs)
        
        nodes = []
        for doc in all_docs:
            is_source = doc in self.file_names
            cited_count = citation_counts.get(doc, 0)
            nodes.append({
                "id": doc,
                "label": doc[:20] + "..." if len(doc) > 20 else doc,
                "size": 10 + cited_count * 5,
                "type": "source" if is_source else "cited",
                "cited_count": cited_count
            })
        
        # æ„å»ºè¾¹åˆ—è¡¨
        edges = []
        for source_doc, cited_docs in self._citation_network.items():
            for cited_doc in cited_docs:
                edges.append({
                    "source": source_doc,
                    "target": cited_doc
                })
        
        return nodes, edges


# ============================================================================
# Streamlit UI æ¸²æŸ“å‡½æ•°
# ============================================================================

def render_citation_analyzer():
    """
    æ¸²æŸ“å¼•ç”¨ä¸å‚è€ƒåˆ†ææ¨¡å—UI
    
    Requirements: 6.4, 6.7
    """
    import streamlit as st
    from utils.session_state import log_message
    
    st.header("ğŸ“– å¼•ç”¨ä¸å‚è€ƒåˆ†æ")
    
    # åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ
    with st.expander("ğŸ“– åŠŸèƒ½ä»‹ç»ä¸æ“ä½œæ‰‹å†Œ", expanded=False):
        st.markdown("""
        ## ğŸ“– å¼•ç”¨ä¸å‚è€ƒåˆ†ææ¨¡å—
        
        **åŠŸèƒ½æ¦‚è¿°**ï¼šåˆ†ææ”¿ç­–æ–‡æœ¬é—´çš„å¼•ç”¨å…³ç³»ï¼Œäº†è§£æ”¿ç­–çš„ä¼ æ‰¿å’Œå½±å“è„‰ç»œã€‚
        
        ---
        
        ### ğŸ¯ ä½¿ç”¨åœºæ™¯
        
        | åœºæ™¯ | å…³æ³¨ç‚¹ | åº”ç”¨ |
        |------|--------|------|
        | æ”¿ç­–æº¯æº | å¼•ç”¨å…³ç³» | è¿½è¸ªæ”¿ç­–çš„æ³•å¾‹ä¾æ® |
        | å½±å“åŠ›åˆ†æ | è¢«å¼•ç”¨æ¬¡æ•° | è¯†åˆ«æ ¸å¿ƒæ”¿ç­–æ–‡ä»¶ |
        | æ”¿ç­–ç½‘ç»œ | å¼•ç”¨ç½‘ç»œ | äº†è§£æ”¿ç­–é—´çš„å…³è” |
        | æ–‡çŒ®ç»¼è¿° | å¼•ç”¨åˆ—è¡¨ | æ•´ç†æ”¿ç­–å‚è€ƒæ–‡çŒ® |
        
        ---
        
        ### ğŸ“‹ æ“ä½œæ­¥éª¤
        
        **1. æå–å¼•ç”¨**ï¼š
        - ç‚¹å‡»"æå–å¼•ç”¨"æŒ‰é’®
        - ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«æ–‡æœ¬ä¸­çš„å¼•ç”¨ï¼ˆå¦‚ã€Šxxxã€‹ã€æ ¹æ®xxxè§„å®šç­‰ï¼‰
        
        **2. æŸ¥çœ‹å¼•ç”¨åˆ—è¡¨**ï¼š
        - æŸ¥çœ‹æ¯ä¸ªæ–‡æ¡£çš„å¼•ç”¨æƒ…å†µ
        - æŸ¥çœ‹å¼•ç”¨ä¸Šä¸‹æ–‡
        
        **3. å¼•ç”¨ç½‘ç»œåˆ†æ**ï¼š
        - æŸ¥çœ‹å¼•ç”¨å…³ç³»æœ‰å‘å›¾
        - è¯†åˆ«æ ¸å¿ƒæ–‡æ¡£ï¼ˆé«˜è¢«å¼•æ–‡æ¡£ï¼‰
        
        **4. å¯¼å‡ºç»“æœ**ï¼š
        - å¯¼å‡ºå¼•ç”¨åˆ—è¡¨
        - å¯¼å‡ºå¼•ç”¨ç½‘ç»œæ•°æ®
        - å¯¼å‡ºå¼•ç”¨ç»Ÿè®¡
        
        ---
        
        ### âš™ï¸ å¼•ç”¨è¯†åˆ«æ¨¡å¼
        
        ç³»ç»Ÿæ”¯æŒè¯†åˆ«ä»¥ä¸‹å¼•ç”¨æ ¼å¼ï¼š
        - ã€Šxxxã€‹æ ¼å¼çš„æ–‡ä»¶å¼•ç”¨
        - "æ ¹æ®xxxè§„å®š"æ ¼å¼
        - "ä¾æ®xxx"æ ¼å¼
        - "æŒ‰ç…§xxxè¦æ±‚"æ ¼å¼
        - "å‚ç…§xxx"æ ¼å¼
        - xxxå·æ–‡æ ¼å¼
        - ã€Šxxxé€šçŸ¥/æ„è§/åŠæ³•ã€‹ç­‰
        
        ---
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè®®
        
        **å­¦æœ¯ç ”ç©¶å»ºè®®**ï¼š
        - æ ¸å¿ƒæ–‡æ¡£é€šå¸¸æ˜¯è¢«å¼•ç”¨æ¬¡æ•°æœ€å¤šçš„æ–‡ä»¶
        - å¼•ç”¨ç½‘ç»œå¯ä»¥æ­ç¤ºæ”¿ç­–çš„å±‚çº§å…³ç³»
        - ç»“åˆæ—¶åºåˆ†æå¯ä»¥è¿½è¸ªæ”¿ç­–æ¼”å˜
        """)
    
    # æ£€æŸ¥æ•°æ®
    if not st.session_state.get("raw_texts"):
        st.warning("âš ï¸ è¯·å…ˆåœ¨ã€Œæ•°æ®åŠ è½½ã€æ ‡ç­¾é¡µä¸­åŠ è½½æ–‡æœ¬æ•°æ®")
        return
    
    raw_texts = st.session_state["raw_texts"]
    file_names = st.session_state.get("file_names", [])
    
    if not file_names:
        st.warning("âš ï¸ æœªæ‰¾åˆ°æ–‡æ¡£åç§°åˆ—è¡¨")
        return
    
    # è·å–æˆ–åˆ›å»ºåˆ†æå™¨
    if "citation_analyzer" not in st.session_state or st.session_state["citation_analyzer"] is None:
        st.session_state["citation_analyzer"] = CitationAnalyzer(raw_texts, file_names)
    
    analyzer = st.session_state["citation_analyzer"]
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tabs = st.tabs([
        "ğŸ” å¼•ç”¨æå–",
        "ğŸ“‹ å¼•ç”¨åˆ—è¡¨",
        "ğŸ•¸ï¸ å¼•ç”¨ç½‘ç»œ",
        "â­ æ ¸å¿ƒæ–‡æ¡£",
        "ğŸ’¾ å¯¼å‡º"
    ])
    
    # ========== å¼•ç”¨æå– ==========
    with tabs[0]:
        st.subheader("å¼•ç”¨æå–")
        
        st.markdown("""
        ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä»æ–‡æœ¬ä¸­è¯†åˆ«å¼•ç”¨å…³ç³»ã€‚
        
        **æ”¯æŒçš„å¼•ç”¨æ ¼å¼**ï¼š
        - ã€Šxxxã€‹æ ¼å¼
        - æ ¹æ®/ä¾æ®/æŒ‰ç…§/å‚ç…§xxx
        - xxxå·æ–‡
        - ç­‰ç­‰...
        """)
        
        if st.button("ğŸ” æå–å¼•ç”¨", type="primary", key="extract_citations"):
            with st.spinner("æ­£åœ¨æå–å¼•ç”¨..."):
                citation_network = analyzer.extract_citations()
                st.session_state["citation_network"] = citation_network
                
                total_citations = len(analyzer.citations)
                docs_with_citations = len([d for d in citation_network.values() if d])
                
                log_message(f"æå–äº† {total_citations} æ¡å¼•ç”¨ï¼Œæ¶‰åŠ {docs_with_citations} ä¸ªæ–‡æ¡£")
                
                st.success(f"âœ… æå–å®Œæˆï¼å…±å‘ç° {total_citations} æ¡å¼•ç”¨")
        
        # æ˜¾ç¤ºæå–ç»Ÿè®¡
        if analyzer.citations:
            st.markdown("---")
            st.subheader("ğŸ“Š æå–ç»Ÿè®¡")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("æ€»å¼•ç”¨æ•°", len(analyzer.citations))
            
            with col2:
                docs_with_citations = len([d for d in analyzer._citation_network.values() if d])
                st.metric("æœ‰å¼•ç”¨çš„æ–‡æ¡£", docs_with_citations)
            
            with col3:
                unique_cited = set()
                for cited_docs in analyzer._citation_network.values():
                    unique_cited.update(cited_docs)
                st.metric("è¢«å¼•ç”¨æ–‡ä»¶æ•°", len(unique_cited))
    
    # ========== å¼•ç”¨åˆ—è¡¨ ==========
    with tabs[1]:
        st.subheader("å¼•ç”¨åˆ—è¡¨")
        
        if not analyzer.citations:
            st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€Œå¼•ç”¨æå–ã€æ ‡ç­¾é¡µä¸­æå–å¼•ç”¨")
            return
        
        # æŒ‰æ–‡æ¡£ç­›é€‰
        selected_doc = st.selectbox(
            "é€‰æ‹©æ–‡æ¡£æŸ¥çœ‹å¼•ç”¨",
            ["å…¨éƒ¨æ–‡æ¡£"] + file_names,
            key="citation_doc_filter"
        )
        
        if selected_doc == "å…¨éƒ¨æ–‡æ¡£":
            citations_to_show = analyzer.citations
        else:
            citations_to_show = analyzer.get_citations_by_document(selected_doc)
        
        if not citations_to_show:
            st.info("è¯¥æ–‡æ¡£æ²¡æœ‰å¼•ç”¨å…¶ä»–æ–‡ä»¶")
        else:
            # æ˜¾ç¤ºå¼•ç”¨åˆ—è¡¨
            st.markdown(f"**å…± {len(citations_to_show)} æ¡å¼•ç”¨**")
            
            for i, citation in enumerate(citations_to_show[:50]):  # æœ€å¤šæ˜¾ç¤º50æ¡
                with st.expander(f"ğŸ“„ {citation.cited_text}", expanded=False):
                    st.markdown(f"**æ¥æºæ–‡æ¡£**: {citation.source_doc}")
                    st.markdown(f"**å¼•ç”¨ä¸Šä¸‹æ–‡**: ...{citation.context}...")
            
            if len(citations_to_show) > 50:
                st.info(f"ä»…æ˜¾ç¤ºå‰50æ¡å¼•ç”¨ï¼Œå…± {len(citations_to_show)} æ¡")
    
    # ========== å¼•ç”¨ç½‘ç»œ ==========
    with tabs[2]:
        st.subheader("å¼•ç”¨ç½‘ç»œå¯è§†åŒ–")
        
        if not analyzer.citations:
            st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€Œå¼•ç”¨æå–ã€æ ‡ç­¾é¡µä¸­æå–å¼•ç”¨")
            return
        
        # è·å–ç½‘ç»œæ•°æ®
        nodes, edges = analyzer.get_network_for_visualization()
        
        if not edges:
            st.info("æœªå‘ç°å¼•ç”¨å…³ç³»")
            return
        
        st.markdown(f"**ç½‘ç»œè§„æ¨¡**: {len(nodes)} ä¸ªèŠ‚ç‚¹, {len(edges)} æ¡è¾¹")
        
        # å°è¯•ä½¿ç”¨pyvisç»˜åˆ¶ç½‘ç»œå›¾
        try:
            from pyvis.network import Network
            import tempfile
            import os
            
            # åˆ›å»ºç½‘ç»œ
            net = Network(height="600px", width="100%", directed=True, 
                         bgcolor="#ffffff", font_color="#333333")
            
            # æ·»åŠ èŠ‚ç‚¹
            for node in nodes:
                color = "#1E88E5" if node["type"] == "source" else "#FFA726"
                net.add_node(
                    node["id"],
                    label=node["label"],
                    size=node["size"],
                    color=color,
                    title=f"{node['id']}\nè¢«å¼•ç”¨: {node['cited_count']}æ¬¡"
                )
            
            # æ·»åŠ è¾¹
            for edge in edges:
                net.add_edge(edge["source"], edge["target"], arrows="to")
            
            # è®¾ç½®ç‰©ç†å¸ƒå±€
            net.set_options("""
            {
                "physics": {
                    "forceAtlas2Based": {
                        "gravitationalConstant": -50,
                        "centralGravity": 0.01,
                        "springLength": 200,
                        "springConstant": 0.08
                    },
                    "maxVelocity": 50,
                    "solver": "forceAtlas2Based",
                    "timestep": 0.35,
                    "stabilization": {"iterations": 150}
                }
            }
            """)
            
            # ä¿å­˜å¹¶æ˜¾ç¤º
            with tempfile.NamedTemporaryFile(delete=False, suffix='.html', mode='w', encoding='utf-8') as f:
                net.save_graph(f.name)
                with open(f.name, 'r', encoding='utf-8') as html_file:
                    html_content = html_file.read()
                st.components.v1.html(html_content, height=620, scrolling=True)
                os.unlink(f.name)
            
            # å›¾ä¾‹
            st.markdown("""
            **å›¾ä¾‹è¯´æ˜**ï¼š
            - ğŸ”µ è“è‰²èŠ‚ç‚¹ï¼šæºæ–‡æ¡£ï¼ˆæ‚¨ä¸Šä¼ çš„æ–‡ä»¶ï¼‰
            - ğŸŸ  æ©™è‰²èŠ‚ç‚¹ï¼šè¢«å¼•ç”¨æ–‡æ¡£
            - ç®­å¤´æ–¹å‘ï¼šä»å¼•ç”¨æ–‡æ¡£æŒ‡å‘è¢«å¼•ç”¨æ–‡æ¡£
            - èŠ‚ç‚¹å¤§å°ï¼šè¢«å¼•ç”¨æ¬¡æ•°è¶Šå¤šï¼ŒèŠ‚ç‚¹è¶Šå¤§
            """)
            
        except ImportError:
            st.warning("ğŸ’¡ å®‰è£… pyvis åº“å¯æ˜¾ç¤ºäº¤äº’å¼ç½‘ç»œå›¾: `pip install pyvis`")
            
            # ä½¿ç”¨ç®€å•çš„è¡¨æ ¼å±•ç¤º
            st.markdown("**å¼•ç”¨å…³ç³»è¡¨**")
            edge_df = pd.DataFrame(edges)
            edge_df.columns = ["å¼•ç”¨æ–‡æ¡£", "è¢«å¼•ç”¨æ–‡æ¡£"]
            st.dataframe(edge_df, use_container_width=True, hide_index=True)
    
    # ========== æ ¸å¿ƒæ–‡æ¡£ ==========
    with tabs[3]:
        st.subheader("æ ¸å¿ƒæ–‡æ¡£è¯†åˆ«")
        
        if not analyzer.citations:
            st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€Œå¼•ç”¨æå–ã€æ ‡ç­¾é¡µä¸­æå–å¼•ç”¨")
            return
        
        # è·å–æ ¸å¿ƒæ–‡æ¡£
        top_n = st.slider("æ˜¾ç¤ºæ ¸å¿ƒæ–‡æ¡£æ•°é‡", 5, 20, 10, key="core_doc_count")
        core_docs = analyzer.find_core_documents(top_n=top_n)
        
        if not core_docs:
            st.info("æœªå‘ç°è¢«å¼•ç”¨çš„æ–‡æ¡£")
            return
        
        st.markdown("**æ ¸å¿ƒæ–‡æ¡£ï¼ˆæŒ‰è¢«å¼•ç”¨æ¬¡æ•°æ’åºï¼‰**")
        
        # æ˜¾ç¤ºæ ¸å¿ƒæ–‡æ¡£åˆ—è¡¨
        core_df = pd.DataFrame(core_docs, columns=["æ–‡æ¡£å", "è¢«å¼•ç”¨æ¬¡æ•°"])
        
        # æ·»åŠ æ’å
        core_df.insert(0, "æ’å", range(1, len(core_df) + 1))
        
        st.dataframe(core_df, use_container_width=True, hide_index=True)
        
        # å¯è§†åŒ–
        if len(core_docs) > 0:
            st.markdown("---")
            st.markdown("**è¢«å¼•ç”¨æ¬¡æ•°åˆ†å¸ƒ**")
            
            try:
                import plotly.express as px
                
                fig = px.bar(
                    core_df,
                    x="æ–‡æ¡£å",
                    y="è¢«å¼•ç”¨æ¬¡æ•°",
                    title="æ ¸å¿ƒæ–‡æ¡£è¢«å¼•ç”¨æ¬¡æ•°",
                    color="è¢«å¼•ç”¨æ¬¡æ•°",
                    color_continuous_scale="Blues"
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig, use_container_width=True)
                
            except ImportError:
                # ä½¿ç”¨StreamlitåŸç”Ÿå›¾è¡¨
                chart_df = core_df.set_index("æ–‡æ¡£å")["è¢«å¼•ç”¨æ¬¡æ•°"]
                st.bar_chart(chart_df)
        
        # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
        st.markdown("---")
        st.subheader("ğŸ“Š è¯¦ç»†å¼•ç”¨ç»Ÿè®¡")
        
        stats = analyzer.get_all_citation_stats()
        stats_data = []
        for stat in stats:
            stats_data.append({
                "æ–‡æ¡£å": stat.doc_name[:30] + "..." if len(stat.doc_name) > 30 else stat.doc_name,
                "è¢«å¼•ç”¨æ¬¡æ•°": stat.cited_by_count,
                "å¼•ç”¨æ¬¡æ•°": stat.cites_count
            })
        
        stats_df = pd.DataFrame(stats_data)
        stats_df = stats_df.sort_values("è¢«å¼•ç”¨æ¬¡æ•°", ascending=False)
        
        st.dataframe(stats_df, use_container_width=True, hide_index=True)
    
    # ========== å¯¼å‡º ==========
    with tabs[4]:
        st.subheader("å¯¼å‡ºå¼•ç”¨åˆ†æç»“æœ")
        
        if not analyzer.citations:
            st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€Œå¼•ç”¨æå–ã€æ ‡ç­¾é¡µä¸­æå–å¼•ç”¨")
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“‹ å¼•ç”¨åˆ—è¡¨**")
            citation_csv = analyzer.export_citation_list()
            if citation_csv:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å¼•ç”¨åˆ—è¡¨CSV",
                    data=citation_csv,
                    file_name="citation_list.csv",
                    mime="text/csv",
                    key="download_citation_list"
                )
            
            st.markdown("**ğŸ•¸ï¸ å¼•ç”¨ç½‘ç»œ**")
            network_csv = analyzer.export_network_data()
            if network_csv:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å¼•ç”¨ç½‘ç»œCSV",
                    data=network_csv,
                    file_name="citation_network.csv",
                    mime="text/csv",
                    key="download_citation_network"
                )
        
        with col2:
            st.markdown("**ğŸ“Š å¼•ç”¨ç»Ÿè®¡**")
            stats_csv = analyzer.export_citation_stats()
            if stats_csv:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å¼•ç”¨ç»Ÿè®¡CSV",
                    data=stats_csv,
                    file_name="citation_stats.csv",
                    mime="text/csv",
                    key="download_citation_stats"
                )
            
            st.markdown("**ğŸ“‘ å¼•ç”¨çŸ©é˜µ**")
            matrix_df, doc_list = analyzer.get_citation_matrix()
            if not matrix_df.empty:
                matrix_csv = matrix_df.to_csv(encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å¼•ç”¨çŸ©é˜µCSV",
                    data=matrix_csv,
                    file_name="citation_matrix.csv",
                    mime="text/csv",
                    key="download_citation_matrix"
                )
